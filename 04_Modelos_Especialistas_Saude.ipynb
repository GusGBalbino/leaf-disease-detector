{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelos Especialistas\n",
        "\n",
        "**Objetivo**: Criar modelos especialistas que classificam em:\n",
        "- **HEALTHY**: Planta saud√°vel\n",
        "- **UNHEALTHY**: Planta doente (qualquer doen√ßa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-04 16:40:36.638827: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751658036.837159   91588 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751658036.889046   91588 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1751658037.527373   91588 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1751658037.527425   91588 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1751658037.527427   91588 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1751658037.527429   91588 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-07-04 16:40:37.567873: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== CARREGANDO DATASETS BIN√ÅRIOS CORRIGIDOS ===\n",
            "üìÇ Carregando dataset de tomato...\n",
            "   ü¶† Tomato_Bacterial_spot: 2127 ‚Üí UNHEALTHY\n",
            "   ü¶† Tomato_Early_blight: 1000 ‚Üí UNHEALTHY\n",
            "   ü¶† Tomato_Late_blight: 1909 ‚Üí UNHEALTHY\n",
            "   ü¶† Tomato_Leaf_Mold: 952 ‚Üí UNHEALTHY\n",
            "   ü¶† Tomato_Septoria_leaf_spot: 1771 ‚Üí UNHEALTHY\n",
            "   ü¶† Tomato_Spider_mites_Two_spotted_spider_mite: 1676 ‚Üí UNHEALTHY\n",
            "   ü¶† Tomato__Target_Spot: 1404 ‚Üí UNHEALTHY\n",
            "   ü¶† Tomato__Tomato_YellowLeaf__Curl_Virus: 3208 ‚Üí UNHEALTHY\n",
            "   ü¶† Tomato__Tomato_mosaic_virus: 373 ‚Üí UNHEALTHY\n",
            "   ‚úÖ Tomato_healthy: 1591 ‚Üí HEALTHY\n",
            "   üìä Total: 16011 | Healthy: 1591 (9.9%) | Unhealthy: 14420 (90.1%)\n",
            "\n",
            "üìÇ Carregando dataset de potato...\n",
            "   ü¶† Potato___Early_blight: 1000 ‚Üí UNHEALTHY\n",
            "   ü¶† Potato___Late_blight: 1000 ‚Üí UNHEALTHY\n",
            "   ‚úÖ Potato___healthy: 152 ‚Üí HEALTHY\n",
            "   üìä Total: 2152 | Healthy: 152 (7.1%) | Unhealthy: 2000 (92.9%)\n",
            "\n",
            "üìÇ Carregando dataset de pepper_bell...\n",
            "   ü¶† Pepper__bell___Bacterial_spot: 997 ‚Üí UNHEALTHY\n",
            "   ‚úÖ Pepper__bell___healthy: 1478 ‚Üí HEALTHY\n",
            "   üìä Total: 2475 | Healthy: 1478 (59.7%) | Unhealthy: 997 (40.3%)\n",
            "\n",
            "‚úÖ DATASETS BIN√ÅRIOS CARREGADOS: Tomato, Potato, Pepper\n"
          ]
        }
      ],
      "source": [
        "# 1. CARREGAMENTO DE DADOS\n",
        "from utils import *\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import pandas as pd\n",
        "\n",
        "config = carregar_configuracoes()\n",
        "\n",
        "def carregar_dataset(especie):\n",
        "    \"\"\"Carrega dataset agrupando todas as doen√ßas\"\"\"\n",
        "    print(f\"üìÇ Carregando dataset de {especie}...\")\n",
        "    \n",
        "    # Construir dataset_info\n",
        "    dataset_info = {}\n",
        "    for esp, info in config['especialistas'].items():\n",
        "        for classe in info['classes']:\n",
        "            dataset_info[classe] = {}\n",
        "    \n",
        "    healthy_images = []\n",
        "    unhealthy_images = []\n",
        "    \n",
        "    # Processar cada classe da esp√©cie\n",
        "    for classe, info in dataset_info.items():\n",
        "        # Remover underscores \n",
        "        classe_normalizada = classe.lower().replace('_', '')\n",
        "        especie_normalizada = especie.lower().replace('_', '')\n",
        "        \n",
        "        if especie_normalizada in classe_normalizada:\n",
        "            # Usar base_path como diret√≥rio base das imagens\n",
        "            dir_path = os.path.join(config.get('processed_data_path', config['base_path']), classe)\n",
        "            \n",
        "            if not os.path.exists(dir_path):\n",
        "                print(f\"   ‚ö†Ô∏è Diret√≥rio n√£o encontrado: {dir_path}\")\n",
        "                continue\n",
        "                \n",
        "            images_in_dir = []\n",
        "            for img_name in os.listdir(dir_path):\n",
        "                if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    images_in_dir.append(os.path.join(dir_path, img_name))\n",
        "            \n",
        "            # AGRUPAMENTO BIN√ÅRIO\n",
        "            if 'healthy' in classe.lower():\n",
        "                healthy_images.extend(images_in_dir)\n",
        "                print(f\"   ‚úÖ {classe}: {len(images_in_dir)} ‚Üí HEALTHY\")\n",
        "            else:\n",
        "                unhealthy_images.extend(images_in_dir)\n",
        "                print(f\"   ü¶† {classe}: {len(images_in_dir)} ‚Üí UNHEALTHY\")\n",
        "    \n",
        "    # Combinar dados\n",
        "    all_images = healthy_images + unhealthy_images\n",
        "    all_labels = ['healthy'] * len(healthy_images) + ['unhealthy'] * len(unhealthy_images)\n",
        "    \n",
        "    # Prote√ß√£o contra divis√£o por zero\n",
        "    if len(all_images) == 0:\n",
        "        print(f\"   ‚ùå ERRO: Nenhuma imagem encontrada para {especie}!\")\n",
        "        print(f\"   üîç Verifique se as pastas existem e cont√™m imagens.\")\n",
        "        return None\n",
        "    \n",
        "    balance_ratio = len(healthy_images) / len(all_images) * 100\n",
        "    print(f\"   üìä Total: {len(all_images)} | Healthy: {len(healthy_images)} ({balance_ratio:.1f}%) | Unhealthy: {len(unhealthy_images)} ({100-balance_ratio:.1f}%)\")\n",
        "    \n",
        "    # Dividindo em treino, valida√ß√£o e teste para todos os datasets\n",
        "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "        all_images, all_labels, test_size=0.15, stratify=all_labels, random_state=42\n",
        "    )\n",
        "    \n",
        "    # Dividindo em treino, valida√ß√£o e teste para cada dataset\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_temp, y_temp, test_size=0.176, stratify=y_temp, random_state=42\n",
        "    )\n",
        "    \n",
        "    return {\n",
        "        'train': {'X': X_train, 'y': y_train},\n",
        "        'val': {'X': X_val, 'y': y_val},\n",
        "        'test': {'X': X_test, 'y': y_test},\n",
        "        'info': {'balance_ratio': balance_ratio, 'total': len(all_images)}\n",
        "    }\n",
        "\n",
        "# Carregar datasets bin√°rios reais\n",
        "print(\"=== CARREGANDO DATASETS BIN√ÅRIOS CORRIGIDOS ===\")\n",
        "dataset_tomato = carregar_dataset('tomato')\n",
        "print()\n",
        "dataset_potato = carregar_dataset('potato')\n",
        "print()\n",
        "dataset_pepper = carregar_dataset('pepper_bell')\n",
        "\n",
        "# Verificar se todos os datasets foram carregados com sucesso\n",
        "datasets_validos = []\n",
        "if dataset_tomato is not None:\n",
        "    datasets_validos.append('Tomato')\n",
        "if dataset_potato is not None:\n",
        "    datasets_validos.append('Potato')    \n",
        "if dataset_pepper is not None:\n",
        "    datasets_validos.append('Pepper')\n",
        "\n",
        "if len(datasets_validos) > 0:\n",
        "    print(f\"\\n‚úÖ DATASETS BIN√ÅRIOS CARREGADOS: {', '.join(datasets_validos)}\")\n",
        "else:\n",
        "    print(\"\\n‚ùå ERRO: Nenhum dataset foi carregado com sucesso!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== CRIANDO GERADORES BIN√ÅRIOS OTIMIZADOS ===\n",
            "Found 11213 validated image filenames belonging to 2 classes.\n",
            "Found 2396 validated image filenames belonging to 2 classes.\n",
            "Found 2402 validated image filenames belonging to 2 classes.\n",
            "Found 1507 validated image filenames belonging to 2 classes.\n",
            "Found 322 validated image filenames belonging to 2 classes.\n",
            "Found 323 validated image filenames belonging to 2 classes.\n",
            "Found 1732 validated image filenames belonging to 2 classes.\n",
            "Found 371 validated image filenames belonging to 2 classes.\n",
            "Found 372 validated image filenames belonging to 2 classes.\n",
            "‚úÖ Geradores criados com class_mode='binary'\n",
            "\n",
            "=== CRIANDO MODELOS BIN√ÅRIOS OTIMIZADOS ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1751658047.715561   91588 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4047 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Modelo bin√°rio Tomato: 24,136,961 par√¢metros\n",
            "‚úÖ Modelo bin√°rio Potato: 24,136,961 par√¢metros\n",
            "‚úÖ Modelo bin√°rio Pepper: 24,136,961 par√¢metros\n",
            "\n",
            "=== CALCULANDO CLASS WEIGHTS ===\n",
            "   Class weights: Healthy=5.033, Unhealthy=0.555\n",
            "   Class weights: Healthy=7.108, Unhealthy=0.538\n",
            "   Class weights: Healthy=0.838, Unhealthy=1.241\n"
          ]
        }
      ],
      "source": [
        "# 2. ARQUITETURA E TREINAMENTO OTIMIZADO\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def criar_classificao_binaria(dataset, config):\n",
        "    \"\"\"Cria geradores otimizados para classifica√ß√£o bin√°ria\"\"\"\n",
        "    \n",
        "    # Data augmentation para generaliza√ß√£o\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=30,\n",
        "        width_shift_range=0.3,\n",
        "        height_shift_range=0.3,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        zoom_range=0.3,\n",
        "        brightness_range=[0.7, 1.3],\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "    \n",
        "    val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    \n",
        "    # DataFrames\n",
        "    train_df = pd.DataFrame({'filename': dataset['train']['X'], 'class': dataset['train']['y']})\n",
        "    val_df = pd.DataFrame({'filename': dataset['val']['X'], 'class': dataset['val']['y']})\n",
        "    test_df = pd.DataFrame({'filename': dataset['test']['X'], 'class': dataset['test']['y']})\n",
        "    \n",
        "    # Geradores bin√°rios\n",
        "    train_gen = train_datagen.flow_from_dataframe(\n",
        "        train_df, x_col='filename', y_col='class',\n",
        "        target_size=(config['img_height'], config['img_width']),\n",
        "        batch_size=config['batch_size'],\n",
        "        class_mode='binary', shuffle=True, seed=42\n",
        "    )\n",
        "    \n",
        "    val_gen = val_test_datagen.flow_from_dataframe(\n",
        "        val_df, x_col='filename', y_col='class',\n",
        "        target_size=(config['img_height'], config['img_width']),\n",
        "        batch_size=config['batch_size'],\n",
        "        class_mode='binary', shuffle=False, seed=42\n",
        "    )\n",
        "    \n",
        "    test_gen = val_test_datagen.flow_from_dataframe(\n",
        "        test_df, x_col='filename', y_col='class',\n",
        "        target_size=(config['img_height'], config['img_width']),\n",
        "        batch_size=config['batch_size'],\n",
        "        class_mode='binary', shuffle=False, seed=42\n",
        "    )\n",
        "    \n",
        "    return train_gen, val_gen, test_gen\n",
        "\n",
        "def criar_modelo(especie_nome):\n",
        "    \"\"\"Cria modelo de classifica√ß√£o bin√°ria\"\"\"\n",
        "    base_model = ResNet50(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(224, 224, 3)\n",
        "    )\n",
        "    \n",
        "    # Descongelar √∫ltimas camadas\n",
        "    base_model.trainable = True\n",
        "    for layer in base_model.layers[:-15]:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    # Arquitetura otimizada para classifica√ß√£o bin√°ria\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "    x = Dropout(0.6)(x)\n",
        "    x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    \n",
        "    # Sa√≠da bin√°ria com sigmoid\n",
        "    predictions = Dense(1, activation='sigmoid', name=f'output_{especie_nome}')(x)\n",
        "    \n",
        "    modelo = Model(inputs=base_model.input, outputs=predictions)\n",
        "    \n",
        "    print(f\"‚úÖ Modelo bin√°rio {especie_nome}: {modelo.count_params():,} par√¢metros\")\n",
        "    return modelo\n",
        "\n",
        "def calcular_class_weights(dataset):\n",
        "    \"\"\"Calcula class weights balanceados\"\"\"\n",
        "    healthy_count = sum(1 for label in dataset['train']['y'] if label == 'healthy')\n",
        "    unhealthy_count = len(dataset['train']['y']) - healthy_count\n",
        "    \n",
        "    total = len(dataset['train']['y'])\n",
        "    weight_healthy = total / (2 * healthy_count)\n",
        "    weight_unhealthy = total / (2 * unhealthy_count)\n",
        "    \n",
        "    class_weights = {0: weight_healthy, 1: weight_unhealthy}  # 0=healthy, 1=unhealthy\n",
        "    \n",
        "    print(f\"   Class weights: Healthy={weight_healthy:.3f}, Unhealthy={weight_unhealthy:.3f}\")\n",
        "    return class_weights\n",
        "\n",
        "# Criar geradores\n",
        "print(\"=== CRIANDO GERADORES BIN√ÅRIOS OTIMIZADOS ===\")\n",
        "train_gen_tomato, val_gen_tomato, test_gen_tomato = criar_classificao_binaria(dataset_tomato, config)\n",
        "train_gen_potato, val_gen_potato, test_gen_potato = criar_classificao_binaria(dataset_potato, config)\n",
        "train_gen_pepper, val_gen_pepper, test_gen_pepper = criar_classificao_binaria(dataset_pepper, config)\n",
        "\n",
        "print(f\"‚úÖ Geradores criados com class_mode='binary'\")\n",
        "\n",
        "# Criar modelos\n",
        "print(\"\\n=== CRIANDO MODELOS BIN√ÅRIOS OTIMIZADOS ===\")\n",
        "modelo_tomato = criar_modelo('Tomato')\n",
        "modelo_potato = criar_modelo('Potato')\n",
        "modelo_pepper = criar_modelo('Pepper')\n",
        "\n",
        "# Calcular class weights\n",
        "print(\"\\n=== CALCULANDO CLASS WEIGHTS ===\")\n",
        "cw_tomato = calcular_class_weights(dataset_tomato)\n",
        "cw_potato = calcular_class_weights(dataset_potato)\n",
        "cw_pepper = calcular_class_weights(dataset_pepper)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== TREINAMENTO DOS MODELOS BIN√ÅRIOS ===\n",
            "\n",
            "üöÄ Treinando Tomato...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/gustavo/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1751658064.893937   91725 service.cc:152] XLA service 0x782368001cf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1751658064.894102   91725 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
            "2025-07-04 16:41:05.472271: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1751658067.491434   91725 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
            "2025-07-04 16:41:12.010729: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.165 = (f32[32,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,56,56]{3,2,1,0} %bitcast.14083, f32[64,64,3,3]{3,2,1,0} %bitcast.14090, f32[64]{0} %bitcast.14092), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 16:41:12.548649: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.175 = (f32[32,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,28,28]{3,2,1,0} %bitcast.14488, f32[128,128,3,3]{3,2,1,0} %bitcast.14495, f32[128]{0} %bitcast.14497), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv3_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 16:41:13.077604: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.188 = (f32[32,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,256,14,14]{3,2,1,0} %bitcast.15016, f32[256,256,3,3]{3,2,1,0} %bitcast.15023, f32[256]{0} %bitcast.15025), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv4_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 16:41:13.606642: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.207 = (f32[32,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,512,7,7]{3,2,1,0} %bitcast.15790, f32[512,512,3,3]{3,2,1,0} %bitcast.15797, f32[512]{0} %bitcast.15799), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv5_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "I0000 00:00:1751658079.018848   91725 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 32/351\u001b[0m \u001b[32m‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m1:58\u001b[0m 370ms/step - accuracy: 0.7624 - loss: 1.6361"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-04 16:41:33.329343: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.165 = (f32[13,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[13,64,56,56]{3,2,1,0} %bitcast.14083, f32[64,64,3,3]{3,2,1,0} %bitcast.14090, f32[64]{0} %bitcast.14092), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 16:41:33.609727: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.175 = (f32[13,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[13,128,28,28]{3,2,1,0} %bitcast.14488, f32[128,128,3,3]{3,2,1,0} %bitcast.14495, f32[128]{0} %bitcast.14497), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv3_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 16:41:33.961813: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.188 = (f32[13,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[13,256,14,14]{3,2,1,0} %bitcast.15016, f32[256,256,3,3]{3,2,1,0} %bitcast.15023, f32[256]{0} %bitcast.15025), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv4_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 16:41:34.297160: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.207 = (f32[13,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[13,512,7,7]{3,2,1,0} %bitcast.15790, f32[512,512,3,3]{3,2,1,0} %bitcast.15797, f32[512]{0} %bitcast.15799), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv5_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.7519 - loss: 1.3425"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-04 16:43:26.339048: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.162 = (f32[28,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[28,64,56,56]{3,2,1,0} %bitcast.4834, f32[64,64,3,3]{3,2,1,0} %bitcast.4841, f32[64]{0} %bitcast.4843), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 16:43:26.719547: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.172 = (f32[28,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[28,128,28,28]{3,2,1,0} %bitcast.5239, f32[128,128,3,3]{3,2,1,0} %bitcast.5246, f32[128]{0} %bitcast.5248), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv3_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 16:43:27.150188: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.185 = (f32[28,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[28,256,14,14]{3,2,1,0} %bitcast.5767, f32[256,256,3,3]{3,2,1,0} %bitcast.5774, f32[256]{0} %bitcast.5776), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv4_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 16:43:27.577535: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.204 = (f32[28,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[28,512,7,7]{3,2,1,0} %bitcast.6541, f32[512,512,3,3]{3,2,1,0} %bitcast.6548, f32[512]{0} %bitcast.6550), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv5_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 374ms/step - accuracy: 0.7519 - loss: 1.3421 - val_accuracy: 0.7350 - val_loss: 1.0823 - learning_rate: 1.0000e-04\n",
            "Epoch 2/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.7881 - loss: 1.0136"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 284ms/step - accuracy: 0.7881 - loss: 1.0136 - val_accuracy: 0.7600 - val_loss: 1.0321 - learning_rate: 1.0000e-04\n",
            "Epoch 3/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 277ms/step - accuracy: 0.8140 - loss: 0.9601 - val_accuracy: 0.7008 - val_loss: 1.1651 - learning_rate: 1.0000e-04\n",
            "Epoch 4/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.8224 - loss: 0.8919"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 283ms/step - accuracy: 0.8224 - loss: 0.8919 - val_accuracy: 0.8819 - val_loss: 0.7567 - learning_rate: 1.0000e-04\n",
            "Epoch 5/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 271ms/step - accuracy: 0.8266 - loss: 0.8906 - val_accuracy: 0.8418 - val_loss: 0.8384 - learning_rate: 1.0000e-04\n",
            "Epoch 6/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.8393 - loss: 0.8378"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 271ms/step - accuracy: 0.8393 - loss: 0.8378 - val_accuracy: 0.9416 - val_loss: 0.6425 - learning_rate: 1.0000e-04\n",
            "Epoch 7/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 270ms/step - accuracy: 0.8337 - loss: 0.8163 - val_accuracy: 0.6874 - val_loss: 1.2138 - learning_rate: 1.0000e-04\n",
            "Epoch 8/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 265ms/step - accuracy: 0.8570 - loss: 0.7876 - val_accuracy: 0.6302 - val_loss: 1.2344 - learning_rate: 1.0000e-04\n",
            "Epoch 9/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 270ms/step - accuracy: 0.8537 - loss: 0.7458 - val_accuracy: 0.8894 - val_loss: 0.7024 - learning_rate: 1.0000e-04\n",
            "Epoch 10/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.8647 - loss: 0.7314"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 286ms/step - accuracy: 0.8647 - loss: 0.7314 - val_accuracy: 0.9491 - val_loss: 0.8514 - learning_rate: 1.0000e-04\n",
            "Epoch 11/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 269ms/step - accuracy: 0.8508 - loss: 0.7207 - val_accuracy: 0.5351 - val_loss: 1.8211 - learning_rate: 1.0000e-04\n",
            "Epoch 12/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 296ms/step - accuracy: 0.8579 - loss: 0.7108 - val_accuracy: 0.8210 - val_loss: 0.7746 - learning_rate: 1.0000e-04\n",
            "Epoch 13/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 275ms/step - accuracy: 0.8663 - loss: 0.6704 - val_accuracy: 0.3502 - val_loss: 1.9857 - learning_rate: 3.0000e-05\n",
            "Epoch 14/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 276ms/step - accuracy: 0.8862 - loss: 0.6262 - val_accuracy: 0.6215 - val_loss: 1.2774 - learning_rate: 3.0000e-05\n",
            "Epoch 15/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 266ms/step - accuracy: 0.8886 - loss: 0.6415 - val_accuracy: 0.6903 - val_loss: 1.0694 - learning_rate: 3.0000e-05\n",
            "Epoch 16/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 280ms/step - accuracy: 0.8818 - loss: 0.6407 - val_accuracy: 0.7008 - val_loss: 1.0488 - learning_rate: 3.0000e-05\n",
            "Epoch 17/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 277ms/step - accuracy: 0.8912 - loss: 0.6123 - val_accuracy: 0.7250 - val_loss: 0.9853 - learning_rate: 3.0000e-05\n",
            "Epoch 18/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 273ms/step - accuracy: 0.8943 - loss: 0.5953 - val_accuracy: 0.8911 - val_loss: 0.5997 - learning_rate: 3.0000e-05\n",
            "Epoch 19/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 279ms/step - accuracy: 0.8903 - loss: 0.5931 - val_accuracy: 0.5710 - val_loss: 1.4373 - learning_rate: 3.0000e-05\n",
            "Epoch 20/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 290ms/step - accuracy: 0.9043 - loss: 0.5606 - val_accuracy: 0.8568 - val_loss: 0.6698 - learning_rate: 3.0000e-05\n",
            "Epoch 21/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 294ms/step - accuracy: 0.9052 - loss: 0.5599 - val_accuracy: 0.8402 - val_loss: 0.7393 - learning_rate: 3.0000e-05\n",
            "Epoch 22/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 308ms/step - accuracy: 0.8993 - loss: 0.5504 - val_accuracy: 0.5977 - val_loss: 1.3277 - learning_rate: 3.0000e-05\n",
            "Epoch 23/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 309ms/step - accuracy: 0.8995 - loss: 0.5592 - val_accuracy: 0.6106 - val_loss: 1.3679 - learning_rate: 3.0000e-05\n",
            "Epoch 24/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 296ms/step - accuracy: 0.9011 - loss: 0.5312 - val_accuracy: 0.7487 - val_loss: 0.9310 - learning_rate: 3.0000e-05\n",
            "Epoch 25/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 268ms/step - accuracy: 0.9035 - loss: 0.5302 - val_accuracy: 0.4967 - val_loss: 1.7694 - learning_rate: 9.0000e-06\n",
            "‚úÖ Tomato conclu√≠do! Melhor accuracy: 0.9491\n",
            "\n",
            "üöÄ Treinando Potato...\n",
            "Epoch 1/40\n",
            "\u001b[1m 2/48\u001b[0m \u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5703 - loss: 1.5237  "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-04 17:23:20.511479: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.175 = (f32[3,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[3,128,28,28]{3,2,1,0} %bitcast.14488, f32[128,128,3,3]{3,2,1,0} %bitcast.14495, f32[128]{0} %bitcast.14497), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv3_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:23:20.725314: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.188 = (f32[3,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[3,256,14,14]{3,2,1,0} %bitcast.15016, f32[256,256,3,3]{3,2,1,0} %bitcast.15023, f32[256]{0} %bitcast.15025), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv4_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:23:20.969040: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.207 = (f32[3,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[3,512,7,7]{3,2,1,0} %bitcast.15790, f32[512,512,3,3]{3,2,1,0} %bitcast.15797, f32[512]{0} %bitcast.15799), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv5_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.5972 - loss: 1.6591"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-04 17:23:41.166511: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.172 = (f32[2,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[2,128,28,28]{3,2,1,0} %bitcast.5241, f32[128,128,3,3]{3,2,1,0} %bitcast.5248, f32[128]{0} %bitcast.5250), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv3_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:23:41.413771: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.185 = (f32[2,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[2,256,14,14]{3,2,1,0} %bitcast.5769, f32[256,256,3,3]{3,2,1,0} %bitcast.5776, f32[256]{0} %bitcast.5778), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv4_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:23:41.621579: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.204 = (f32[2,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[2,512,7,7]{3,2,1,0} %bitcast.6543, f32[512,512,3,3]{3,2,1,0} %bitcast.6550, f32[512]{0} %bitcast.6552), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv5_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 602ms/step - accuracy: 0.5976 - loss: 1.6578 - val_accuracy: 0.0714 - val_loss: 1.3178 - learning_rate: 1.0000e-04\n",
            "Epoch 2/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.6073 - loss: 1.3944"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 304ms/step - accuracy: 0.6073 - loss: 1.3951 - val_accuracy: 0.9286 - val_loss: 1.1882 - learning_rate: 1.0000e-04\n",
            "Epoch 3/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 266ms/step - accuracy: 0.5881 - loss: 1.4069 - val_accuracy: 0.4503 - val_loss: 1.2599 - learning_rate: 1.0000e-04\n",
            "Epoch 4/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 271ms/step - accuracy: 0.6040 - loss: 1.3787 - val_accuracy: 0.9224 - val_loss: 1.0963 - learning_rate: 1.0000e-04\n",
            "Epoch 5/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 261ms/step - accuracy: 0.5943 - loss: 1.4672 - val_accuracy: 0.9255 - val_loss: 0.9806 - learning_rate: 1.0000e-04\n",
            "Epoch 6/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 271ms/step - accuracy: 0.6216 - loss: 1.3126 - val_accuracy: 0.7019 - val_loss: 1.1101 - learning_rate: 1.0000e-04\n",
            "Epoch 7/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 288ms/step - accuracy: 0.6093 - loss: 1.3625 - val_accuracy: 0.7857 - val_loss: 1.0915 - learning_rate: 1.0000e-04\n",
            "Epoch 8/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 281ms/step - accuracy: 0.6338 - loss: 1.4514 - val_accuracy: 0.8478 - val_loss: 0.9867 - learning_rate: 1.0000e-04\n",
            "Epoch 9/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 276ms/step - accuracy: 0.6695 - loss: 1.2951 - val_accuracy: 0.8416 - val_loss: 0.9388 - learning_rate: 1.0000e-04\n",
            "Epoch 10/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 262ms/step - accuracy: 0.6733 - loss: 1.2971 - val_accuracy: 0.9099 - val_loss: 0.8585 - learning_rate: 1.0000e-04\n",
            "Epoch 11/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 295ms/step - accuracy: 0.6195 - loss: 1.2532 - val_accuracy: 0.9224 - val_loss: 0.8096 - learning_rate: 1.0000e-04\n",
            "Epoch 12/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 267ms/step - accuracy: 0.6585 - loss: 1.2434 - val_accuracy: 0.9255 - val_loss: 0.7607 - learning_rate: 1.0000e-04\n",
            "Epoch 13/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 272ms/step - accuracy: 0.6428 - loss: 1.1595 - val_accuracy: 0.8168 - val_loss: 0.9568 - learning_rate: 1.0000e-04\n",
            "Epoch 14/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 271ms/step - accuracy: 0.6875 - loss: 1.1785 - val_accuracy: 0.5404 - val_loss: 1.3784 - learning_rate: 1.0000e-04\n",
            "Epoch 15/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 262ms/step - accuracy: 0.6623 - loss: 1.1546 - val_accuracy: 0.7391 - val_loss: 1.0327 - learning_rate: 1.0000e-04\n",
            "Epoch 16/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 286ms/step - accuracy: 0.6585 - loss: 1.1083 - val_accuracy: 0.9037 - val_loss: 0.8134 - learning_rate: 1.0000e-04\n",
            "Epoch 17/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 273ms/step - accuracy: 0.6899 - loss: 1.2261 - val_accuracy: 0.4348 - val_loss: 1.5789 - learning_rate: 1.0000e-04\n",
            "‚úÖ Potato conclu√≠do! Melhor accuracy: 0.9286\n",
            "\n",
            "üöÄ Treinando Pepper...\n",
            "Epoch 1/40\n",
            "\u001b[1m16/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m11s\u001b[0m 304ms/step - accuracy: 0.5177 - loss: 1.5555"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-04 17:27:39.478855: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.165 = (f32[4,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,64,56,56]{3,2,1,0} %bitcast.14083, f32[64,64,3,3]{3,2,1,0} %bitcast.14090, f32[64]{0} %bitcast.14092), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv2_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:27:39.713344: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.175 = (f32[4,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,128,28,28]{3,2,1,0} %bitcast.14488, f32[128,128,3,3]{3,2,1,0} %bitcast.14495, f32[128]{0} %bitcast.14497), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv3_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:27:39.945101: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.188 = (f32[4,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,256,14,14]{3,2,1,0} %bitcast.15016, f32[256,256,3,3]{3,2,1,0} %bitcast.15023, f32[256]{0} %bitcast.15025), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv4_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:27:40.201681: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.207 = (f32[4,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,512,7,7]{3,2,1,0} %bitcast.15790, f32[512,512,3,3]{3,2,1,0} %bitcast.15797, f32[512]{0} %bitcast.15799), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv5_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.5351 - loss: 1.5450"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-04 17:27:57.722303: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.162 = (f32[19,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[19,64,56,56]{3,2,1,0} %bitcast.4834, f32[64,64,3,3]{3,2,1,0} %bitcast.4841, f32[64]{0} %bitcast.4843), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv2_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:27:57.996689: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.172 = (f32[19,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[19,128,28,28]{3,2,1,0} %bitcast.5239, f32[128,128,3,3]{3,2,1,0} %bitcast.5246, f32[128]{0} %bitcast.5248), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv3_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:27:58.292243: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.185 = (f32[19,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[19,256,14,14]{3,2,1,0} %bitcast.5767, f32[256,256,3,3]{3,2,1,0} %bitcast.5774, f32[256]{0} %bitcast.5776), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv4_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:27:58.588142: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.204 = (f32[19,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[19,512,7,7]{3,2,1,0} %bitcast.6541, f32[512,512,3,3]{3,2,1,0} %bitcast.6548, f32[512]{0} %bitcast.6550), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv5_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 589ms/step - accuracy: 0.5357 - loss: 1.5438 - val_accuracy: 0.4016 - val_loss: 1.4879 - learning_rate: 1.0000e-04\n",
            "Epoch 2/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 275ms/step - accuracy: 0.6005 - loss: 1.3824 - val_accuracy: 0.4016 - val_loss: 1.3145 - learning_rate: 1.0000e-04\n",
            "Epoch 3/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.6293 - loss: 1.3334"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 290ms/step - accuracy: 0.6292 - loss: 1.3336 - val_accuracy: 0.7332 - val_loss: 1.1875 - learning_rate: 1.0000e-04\n",
            "Epoch 4/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 280ms/step - accuracy: 0.6192 - loss: 1.3196 - val_accuracy: 0.6334 - val_loss: 1.1955 - learning_rate: 1.0000e-04\n",
            "Epoch 5/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 259ms/step - accuracy: 0.6301 - loss: 1.2981 - val_accuracy: 0.5714 - val_loss: 1.1953 - learning_rate: 1.0000e-04\n",
            "Epoch 6/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 278ms/step - accuracy: 0.6603 - loss: 1.2376 - val_accuracy: 0.6307 - val_loss: 1.1819 - learning_rate: 1.0000e-04\n",
            "Epoch 7/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 257ms/step - accuracy: 0.6726 - loss: 1.1947 - val_accuracy: 0.7332 - val_loss: 1.1466 - learning_rate: 1.0000e-04\n",
            "Epoch 8/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 281ms/step - accuracy: 0.6529 - loss: 1.2193 - val_accuracy: 0.6361 - val_loss: 1.1533 - learning_rate: 1.0000e-04\n",
            "Epoch 9/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.6830 - loss: 1.1827"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 312ms/step - accuracy: 0.6829 - loss: 1.1828 - val_accuracy: 0.7736 - val_loss: 1.1047 - learning_rate: 1.0000e-04\n",
            "Epoch 10/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 278ms/step - accuracy: 0.6968 - loss: 1.1742 - val_accuracy: 0.6900 - val_loss: 1.1325 - learning_rate: 1.0000e-04\n",
            "Epoch 11/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 273ms/step - accuracy: 0.6877 - loss: 1.1415 - val_accuracy: 0.7520 - val_loss: 1.0408 - learning_rate: 1.0000e-04\n",
            "Epoch 12/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 273ms/step - accuracy: 0.6690 - loss: 1.1599 - val_accuracy: 0.7385 - val_loss: 1.0499 - learning_rate: 1.0000e-04\n",
            "Epoch 13/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 261ms/step - accuracy: 0.7073 - loss: 1.1185 - val_accuracy: 0.7278 - val_loss: 1.0655 - learning_rate: 1.0000e-04\n",
            "Epoch 14/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 260ms/step - accuracy: 0.6811 - loss: 1.1507 - val_accuracy: 0.7736 - val_loss: 1.0069 - learning_rate: 1.0000e-04\n",
            "Epoch 15/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 261ms/step - accuracy: 0.6953 - loss: 1.1348 - val_accuracy: 0.7736 - val_loss: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 16/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 251ms/step - accuracy: 0.7022 - loss: 1.1031 - val_accuracy: 0.7466 - val_loss: 1.0407 - learning_rate: 1.0000e-04\n",
            "Epoch 17/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 267ms/step - accuracy: 0.7033 - loss: 1.1067 - val_accuracy: 0.6927 - val_loss: 1.1765 - learning_rate: 1.0000e-04\n",
            "Epoch 18/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 255ms/step - accuracy: 0.6914 - loss: 1.1016 - val_accuracy: 0.7466 - val_loss: 1.0294 - learning_rate: 1.0000e-04\n",
            "Epoch 19/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 269ms/step - accuracy: 0.6971 - loss: 1.1059 - val_accuracy: 0.7682 - val_loss: 1.0199 - learning_rate: 1.0000e-04\n",
            "Epoch 20/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 256ms/step - accuracy: 0.6907 - loss: 1.1185 - val_accuracy: 0.6442 - val_loss: 1.2395 - learning_rate: 1.0000e-04\n",
            "Epoch 21/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.7128 - loss: 1.0910"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 270ms/step - accuracy: 0.7129 - loss: 1.0908 - val_accuracy: 0.7871 - val_loss: 0.9561 - learning_rate: 1.0000e-04\n",
            "Epoch 22/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 258ms/step - accuracy: 0.7249 - loss: 1.0676 - val_accuracy: 0.7628 - val_loss: 0.9912 - learning_rate: 1.0000e-04\n",
            "Epoch 23/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 261ms/step - accuracy: 0.7021 - loss: 1.0956 - val_accuracy: 0.7844 - val_loss: 0.9656 - learning_rate: 1.0000e-04\n",
            "Epoch 24/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 266ms/step - accuracy: 0.6967 - loss: 1.0775 - val_accuracy: 0.7601 - val_loss: 0.9722 - learning_rate: 1.0000e-04\n",
            "Epoch 25/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 264ms/step - accuracy: 0.7300 - loss: 1.0491 - val_accuracy: 0.7763 - val_loss: 0.9466 - learning_rate: 1.0000e-04\n",
            "Epoch 26/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 268ms/step - accuracy: 0.7484 - loss: 1.0519 - val_accuracy: 0.7493 - val_loss: 0.9882 - learning_rate: 1.0000e-04\n",
            "Epoch 27/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 253ms/step - accuracy: 0.7271 - loss: 1.0394 - val_accuracy: 0.7763 - val_loss: 0.9859 - learning_rate: 1.0000e-04\n",
            "Epoch 28/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.7187 - loss: 1.0539"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 281ms/step - accuracy: 0.7187 - loss: 1.0540 - val_accuracy: 0.7951 - val_loss: 0.9396 - learning_rate: 1.0000e-04\n",
            "Epoch 29/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.7546 - loss: 1.0255"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 271ms/step - accuracy: 0.7544 - loss: 1.0257 - val_accuracy: 0.8005 - val_loss: 0.9312 - learning_rate: 1.0000e-04\n",
            "Epoch 30/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 272ms/step - accuracy: 0.7296 - loss: 1.0307 - val_accuracy: 0.7709 - val_loss: 0.9405 - learning_rate: 1.0000e-04\n",
            "Epoch 31/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 261ms/step - accuracy: 0.7530 - loss: 1.0153 - val_accuracy: 0.7089 - val_loss: 1.0445 - learning_rate: 1.0000e-04\n",
            "Epoch 32/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 259ms/step - accuracy: 0.7240 - loss: 1.0455 - val_accuracy: 0.7817 - val_loss: 0.9333 - learning_rate: 1.0000e-04\n",
            "Epoch 33/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 270ms/step - accuracy: 0.7157 - loss: 1.0295 - val_accuracy: 0.7790 - val_loss: 0.9258 - learning_rate: 1.0000e-04\n",
            "Epoch 34/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 260ms/step - accuracy: 0.7453 - loss: 1.0239 - val_accuracy: 0.6119 - val_loss: 1.2557 - learning_rate: 1.0000e-04\n",
            "Epoch 35/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.7446 - loss: 1.0171"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 285ms/step - accuracy: 0.7446 - loss: 1.0169 - val_accuracy: 0.8113 - val_loss: 0.8881 - learning_rate: 1.0000e-04\n",
            "Epoch 36/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 265ms/step - accuracy: 0.7469 - loss: 1.0027 - val_accuracy: 0.6765 - val_loss: 1.3188 - learning_rate: 1.0000e-04\n",
            "Epoch 37/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 270ms/step - accuracy: 0.7502 - loss: 0.9836 - val_accuracy: 0.6981 - val_loss: 0.9937 - learning_rate: 1.0000e-04\n",
            "Epoch 38/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 252ms/step - accuracy: 0.7251 - loss: 1.0074 - val_accuracy: 0.7601 - val_loss: 0.9585 - learning_rate: 1.0000e-04\n",
            "Epoch 39/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 274ms/step - accuracy: 0.7577 - loss: 0.9661 - val_accuracy: 0.6307 - val_loss: 1.2445 - learning_rate: 1.0000e-04\n",
            "Epoch 40/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 250ms/step - accuracy: 0.7387 - loss: 0.9854 - val_accuracy: 0.7116 - val_loss: 1.0102 - learning_rate: 1.0000e-04\n",
            "‚úÖ Pepper conclu√≠do! Melhor accuracy: 0.8113\n",
            "\n",
            "üéØ TODOS OS MODELOS TREINADOS COM SUCESSO!\n"
          ]
        }
      ],
      "source": [
        "# 3. TREINAMENTO OTIMIZADO COM CLASS WEIGHTS\n",
        "def treinar_modelo_binario(modelo, especie, train_gen, val_gen, class_weights):\n",
        "    \"\"\"Treina modelo de classifica√ß√£o bin√°ria com class weights\"\"\"\n",
        "    print(f\"\\nüöÄ Treinando {especie}...\")\n",
        "    \n",
        "    # Compila√ß√£o\n",
        "    modelo.compile(\n",
        "        optimizer=Adam(learning_rate=0.0001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    # Callback\n",
        "    callbacks = [\n",
        "        EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=15,\n",
        "            restore_best_weights=True,\n",
        "            min_delta=0.001\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.3,\n",
        "            patience=6,\n",
        "            min_lr=1e-8\n",
        "        ),\n",
        "        ModelCheckpoint(\n",
        "            filepath=f'modelos_salvos/especialistas/modelo_binario_{especie.lower()}.h5',\n",
        "            monitor='val_accuracy',\n",
        "            save_best_only=True\n",
        "        )\n",
        "    ]\n",
        "    \n",
        "    # Treinamento\n",
        "    history = modelo.fit(\n",
        "        train_gen,\n",
        "        epochs=40,\n",
        "        validation_data=val_gen,\n",
        "        class_weight=class_weights,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "    \n",
        "    final_accuracy = max(history.history['val_accuracy'])\n",
        "    print(f\"‚úÖ {especie} conclu√≠do! Melhor accuracy: {final_accuracy:.4f}\")\n",
        "    \n",
        "    return history\n",
        "\n",
        "# Treinar todos os modelos\n",
        "os.makedirs('modelos_salvos', exist_ok=True)\n",
        "\n",
        "print(\"=== TREINAMENTO DOS MODELOS BIN√ÅRIOS ===\")\n",
        "history_tomato = treinar_modelo_binario(modelo_tomato, 'Tomato', train_gen_tomato, val_gen_tomato, cw_tomato)\n",
        "history_potato = treinar_modelo_binario(modelo_potato, 'Potato', train_gen_potato, val_gen_potato, cw_potato)\n",
        "history_pepper = treinar_modelo_binario(modelo_pepper, 'Pepper', train_gen_pepper, val_gen_pepper, cw_pepper)\n",
        "\n",
        "print(\"\\nüéØ TODOS OS MODELOS TREINADOS COM SUCESSO!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== AVALIA√á√ÉO FINAL DOS MODELOS BIN√ÅRIOS ===\n",
            "\n",
            "üìä Avaliando Tomato...\n",
            "   üéØ Accuracy: 0.9450\n",
            "   üéØ AUC-ROC: 0.8940\n",
            "   üéØ Recall: 0.9894\n",
            "   üéØ Precision: 0.9515\n",
            "   üéØ F1-Score: 0.9701\n",
            "   Matriz: [[130, 109], [ 23, 2140]]\n",
            "\n",
            "   Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Healthy       0.85      0.54      0.66       239\n",
            "   Unhealthy       0.95      0.99      0.97      2163\n",
            "\n",
            "    accuracy                           0.95      2402\n",
            "   macro avg       0.90      0.77      0.82      2402\n",
            "weighted avg       0.94      0.95      0.94      2402\n",
            "\n",
            "\n",
            "üìä Avaliando Potato...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/gustavo/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üéØ Accuracy: 0.9319\n",
            "   üéØ AUC-ROC: 0.7168\n",
            "   üéØ Recall: 0.9933\n",
            "   üéØ Precision: 0.9371\n",
            "   üéØ F1-Score: 0.9644\n",
            "   Matriz: [[  3,  20], [  2, 298]]\n",
            "\n",
            "   Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Healthy       0.60      0.13      0.21        23\n",
            "   Unhealthy       0.94      0.99      0.96       300\n",
            "\n",
            "    accuracy                           0.93       323\n",
            "   macro avg       0.77      0.56      0.59       323\n",
            "weighted avg       0.91      0.93      0.91       323\n",
            "\n",
            "\n",
            "üìä Avaliando Pepper...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/gustavo/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "2025-07-04 17:38:08.358691: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.162 = (f32[20,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[20,64,56,56]{3,2,1,0} %bitcast.4595, f32[64,64,3,3]{3,2,1,0} %bitcast.4602, f32[64]{0} %bitcast.4604), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv2_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:38:08.652111: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.172 = (f32[20,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[20,128,28,28]{3,2,1,0} %bitcast.5000, f32[128,128,3,3]{3,2,1,0} %bitcast.5007, f32[128]{0} %bitcast.5009), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv3_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:38:08.971163: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.185 = (f32[20,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[20,256,14,14]{3,2,1,0} %bitcast.5528, f32[256,256,3,3]{3,2,1,0} %bitcast.5535, f32[256]{0} %bitcast.5537), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv4_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:38:09.287110: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.204 = (f32[20,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[20,512,7,7]{3,2,1,0} %bitcast.6302, f32[512,512,3,3]{3,2,1,0} %bitcast.6309, f32[512]{0} %bitcast.6311), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv5_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üéØ Accuracy: 0.8253\n",
            "   üéØ AUC-ROC: 0.8853\n",
            "   üéØ Recall: 0.7467\n",
            "   üéØ Precision: 0.8058\n",
            "   üéØ F1-Score: 0.7751\n",
            "   Matriz: [[195,  27], [ 38, 112]]\n",
            "\n",
            "   Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Healthy       0.84      0.88      0.86       222\n",
            "   Unhealthy       0.81      0.75      0.78       150\n",
            "\n",
            "    accuracy                           0.83       372\n",
            "   macro avg       0.82      0.81      0.82       372\n",
            "weighted avg       0.82      0.83      0.82       372\n",
            "\n",
            "\n",
            "=== COMPARA√á√ÉO FINAL ===\n",
            "   Tomato: 0.9450 - üü¢ EXCELENTE\n",
            "   Potato: 0.9319 - üü¢ EXCELENTE\n",
            "   Pepper: 0.8253 - üü° BOA\n"
          ]
        }
      ],
      "source": [
        "# 4. AVALIA√á√ÉO DO MODELO\n",
        "from sklearn.metrics import (\n",
        "    classification_report, \n",
        "    accuracy_score, \n",
        "    confusion_matrix, \n",
        "    roc_auc_score, \n",
        "    recall_score, \n",
        "    precision_score, \n",
        "    f1_score\n",
        "    )\n",
        "\n",
        "def avaliar_modelo(modelo, especie, test_gen, dataset_test):\n",
        "    \"\"\"Avalia√ß√£o completa do modelo de classifica√ß√£o bin√°ria\"\"\"\n",
        "    print(f\"\\nüìä Avaliando {especie}...\")\n",
        "    \n",
        "    test_gen.reset()\n",
        "    \n",
        "    # Predi√ß√µes\n",
        "    predictions_prob = modelo.predict(test_gen, verbose=0)\n",
        "    predictions_class = (predictions_prob > 0.5).astype(int).flatten()\n",
        "    \n",
        "    # Classes verdadeiras\n",
        "    true_classes = [1 if label == 'unhealthy' else 0 for label in dataset_test['y']]\n",
        "    \n",
        "    # M√©tricas\n",
        "    accuracy = accuracy_score(true_classes, predictions_class)\n",
        "    auc_score = roc_auc_score(true_classes, predictions_prob)\n",
        "    cm = confusion_matrix(true_classes, predictions_class)\n",
        "    recall = recall_score(true_classes, predictions_class)\n",
        "    precision = precision_score(true_classes, predictions_class)\n",
        "    f1 = f1_score(true_classes, predictions_class)\n",
        "\n",
        "    # M√©tricas m√©dicas\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    \n",
        "    print(f\"   üéØ Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"   üéØ AUC-ROC: {auc_score:.4f}\")\n",
        "    print(f\"   üéØ Recall: {recall:.4f}\")\n",
        "    print(f\"   üéØ Precision: {precision:.4f}\")\n",
        "    print(f\"   üéØ F1-Score: {f1:.4f}\")\n",
        "\n",
        "    \n",
        "    # Matriz de confus√£o\n",
        "    print(f\"   Matriz: [[{tn:3d}, {fp:3d}], [{fn:3d}, {tp:3d}]]\")\n",
        "    \n",
        "    # Relat√≥rio\n",
        "    print(\"\\n   Classification Report:\")\n",
        "    print(classification_report(true_classes, predictions_class, target_names=['Healthy', 'Unhealthy'], zero_division=0))\n",
        "    \n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'auc_roc': auc_score,\n",
        "        'confusion_matrix': cm,\n",
        "        'recall': recall,\n",
        "        'precision': precision,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "# Avaliar todos os modelos\n",
        "print(\"=== AVALIA√á√ÉO FINAL DOS MODELOS BIN√ÅRIOS ===\")\n",
        "resultados_tomato = avaliar_modelo(modelo_tomato, 'Tomato', test_gen_tomato, dataset_tomato['test'])\n",
        "resultados_potato = avaliar_modelo(modelo_potato, 'Potato', test_gen_potato, dataset_potato['test'])\n",
        "resultados_pepper = avaliar_modelo(modelo_pepper, 'Pepper', test_gen_pepper, dataset_pepper['test'])\n",
        "\n",
        "# Compara√ß√£o final\n",
        "print(f\"\\n=== COMPARA√á√ÉO FINAL ===\")\n",
        "resultados = [\n",
        "    ('Tomato', resultados_tomato),\n",
        "    ('Potato', resultados_potato), \n",
        "    ('Pepper', resultados_pepper)\n",
        "]\n",
        "\n",
        "for especie, resultado in resultados:\n",
        "    qualidade = \"üü¢ EXCELENTE\" if resultado['accuracy'] > 0.9 else \"üü° BOA\" if resultado['accuracy'] > 0.7 else \"üî¥ INSUFICIENTE\"\n",
        "    print(f\"   {especie}: {resultado['accuracy']:.4f} - {qualidade}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SALVANDO MODELOS OTIMIZADOS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Salvar modelos finais\n",
        "print(\"SALVANDO MODELOS OTIMIZADOS\")\n",
        "modelo_tomato.save('modelos_salvos/especialistas/especialista_tomato_binario_final.h5')\n",
        "modelo_potato.save('modelos_salvos/especialistas/especialista_potato_binario_final.h5')\n",
        "modelo_pepper.save('modelos_salvos/especialistas/especialista_pepper_binario_final.h5')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
