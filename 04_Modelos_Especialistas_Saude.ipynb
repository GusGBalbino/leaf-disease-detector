{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelos Especialistas\n",
        "\n",
        "**Objetivo**: Criar modelos especialistas que classificam em:\n",
        "- **HEALTHY**: Planta saudÃ¡vel\n",
        "- **UNHEALTHY**: Planta doente (qualquer doenÃ§a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-04 16:40:36.638827: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751658036.837159   91588 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751658036.889046   91588 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1751658037.527373   91588 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1751658037.527425   91588 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1751658037.527427   91588 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1751658037.527429   91588 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-07-04 16:40:37.567873: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== CARREGANDO DATASETS BINÃRIOS CORRIGIDOS ===\n",
            "ðŸ“‚ Carregando dataset de tomato...\n",
            "   ðŸ¦  Tomato_Bacterial_spot: 2127 â†’ UNHEALTHY\n",
            "   ðŸ¦  Tomato_Early_blight: 1000 â†’ UNHEALTHY\n",
            "   ðŸ¦  Tomato_Late_blight: 1909 â†’ UNHEALTHY\n",
            "   ðŸ¦  Tomato_Leaf_Mold: 952 â†’ UNHEALTHY\n",
            "   ðŸ¦  Tomato_Septoria_leaf_spot: 1771 â†’ UNHEALTHY\n",
            "   ðŸ¦  Tomato_Spider_mites_Two_spotted_spider_mite: 1676 â†’ UNHEALTHY\n",
            "   ðŸ¦  Tomato__Target_Spot: 1404 â†’ UNHEALTHY\n",
            "   ðŸ¦  Tomato__Tomato_YellowLeaf__Curl_Virus: 3208 â†’ UNHEALTHY\n",
            "   ðŸ¦  Tomato__Tomato_mosaic_virus: 373 â†’ UNHEALTHY\n",
            "   âœ… Tomato_healthy: 1591 â†’ HEALTHY\n",
            "   ðŸ“Š Total: 16011 | Healthy: 1591 (9.9%) | Unhealthy: 14420 (90.1%)\n",
            "\n",
            "ðŸ“‚ Carregando dataset de potato...\n",
            "   ðŸ¦  Potato___Early_blight: 1000 â†’ UNHEALTHY\n",
            "   ðŸ¦  Potato___Late_blight: 1000 â†’ UNHEALTHY\n",
            "   âœ… Potato___healthy: 152 â†’ HEALTHY\n",
            "   ðŸ“Š Total: 2152 | Healthy: 152 (7.1%) | Unhealthy: 2000 (92.9%)\n",
            "\n",
            "ðŸ“‚ Carregando dataset de pepper_bell...\n",
            "   ðŸ¦  Pepper__bell___Bacterial_spot: 997 â†’ UNHEALTHY\n",
            "   âœ… Pepper__bell___healthy: 1478 â†’ HEALTHY\n",
            "   ðŸ“Š Total: 2475 | Healthy: 1478 (59.7%) | Unhealthy: 997 (40.3%)\n",
            "\n",
            "âœ… DATASETS BINÃRIOS CARREGADOS: Tomato, Potato, Pepper\n"
          ]
        }
      ],
      "source": [
        "# 1. CARREGAMENTO DE DADOS\n",
        "from utils import *\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import pandas as pd\n",
        "\n",
        "config = carregar_configuracoes()\n",
        "\n",
        "def carregar_dataset(especie):\n",
        "    \"\"\"Carrega dataset agrupando todas as doenÃ§as\"\"\"\n",
        "    print(f\"ðŸ“‚ Carregando dataset de {especie}...\")\n",
        "    \n",
        "    # Construir dataset_info\n",
        "    dataset_info = {}\n",
        "    for esp, info in config['especialistas'].items():\n",
        "        for classe in info['classes']:\n",
        "            dataset_info[classe] = {}\n",
        "    \n",
        "    healthy_images = []\n",
        "    unhealthy_images = []\n",
        "    \n",
        "    # Processar cada classe da espÃ©cie\n",
        "    for classe, info in dataset_info.items():\n",
        "        # Remover underscores \n",
        "        classe_normalizada = classe.lower().replace('_', '')\n",
        "        especie_normalizada = especie.lower().replace('_', '')\n",
        "        \n",
        "        if especie_normalizada in classe_normalizada:\n",
        "            # Usar base_path como diretÃ³rio base das imagens\n",
        "            dir_path = os.path.join(config.get('processed_data_path', config['base_path']), classe)\n",
        "            \n",
        "            if not os.path.exists(dir_path):\n",
        "                print(f\"   âš ï¸ DiretÃ³rio nÃ£o encontrado: {dir_path}\")\n",
        "                continue\n",
        "                \n",
        "            images_in_dir = []\n",
        "            for img_name in os.listdir(dir_path):\n",
        "                if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    images_in_dir.append(os.path.join(dir_path, img_name))\n",
        "            \n",
        "            # AGRUPAMENTO BINÃRIO\n",
        "            if 'healthy' in classe.lower():\n",
        "                healthy_images.extend(images_in_dir)\n",
        "                print(f\"   âœ… {classe}: {len(images_in_dir)} â†’ HEALTHY\")\n",
        "            else:\n",
        "                unhealthy_images.extend(images_in_dir)\n",
        "                print(f\"   ðŸ¦  {classe}: {len(images_in_dir)} â†’ UNHEALTHY\")\n",
        "    \n",
        "    # Combinar dados\n",
        "    all_images = healthy_images + unhealthy_images\n",
        "    all_labels = ['healthy'] * len(healthy_images) + ['unhealthy'] * len(unhealthy_images)\n",
        "    \n",
        "    # ProteÃ§Ã£o contra divisÃ£o por zero\n",
        "    if len(all_images) == 0:\n",
        "        print(f\"   âŒ ERRO: Nenhuma imagem encontrada para {especie}!\")\n",
        "        print(f\"   ðŸ” Verifique se as pastas existem e contÃªm imagens.\")\n",
        "        return None\n",
        "    \n",
        "    balance_ratio = len(healthy_images) / len(all_images) * 100\n",
        "    print(f\"   ðŸ“Š Total: {len(all_images)} | Healthy: {len(healthy_images)} ({balance_ratio:.1f}%) | Unhealthy: {len(unhealthy_images)} ({100-balance_ratio:.1f}%)\")\n",
        "    \n",
        "    # Dividindo em treino, validaÃ§Ã£o e teste para todos os datasets\n",
        "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "        all_images, all_labels, test_size=0.15, stratify=all_labels, random_state=42\n",
        "    )\n",
        "    \n",
        "    # Dividindo em treino, validaÃ§Ã£o e teste para cada dataset\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_temp, y_temp, test_size=0.176, stratify=y_temp, random_state=42\n",
        "    )\n",
        "    \n",
        "    return {\n",
        "        'train': {'X': X_train, 'y': y_train},\n",
        "        'val': {'X': X_val, 'y': y_val},\n",
        "        'test': {'X': X_test, 'y': y_test},\n",
        "        'info': {'balance_ratio': balance_ratio, 'total': len(all_images)}\n",
        "    }\n",
        "\n",
        "# Carregar datasets binÃ¡rios reais\n",
        "print(\"=== CARREGANDO DATASETS BINÃRIOS CORRIGIDOS ===\")\n",
        "dataset_tomato = carregar_dataset('tomato')\n",
        "print()\n",
        "dataset_potato = carregar_dataset('potato')\n",
        "print()\n",
        "dataset_pepper = carregar_dataset('pepper_bell')\n",
        "\n",
        "# Verificar se todos os datasets foram carregados com sucesso\n",
        "datasets_validos = []\n",
        "if dataset_tomato is not None:\n",
        "    datasets_validos.append('Tomato')\n",
        "if dataset_potato is not None:\n",
        "    datasets_validos.append('Potato')    \n",
        "if dataset_pepper is not None:\n",
        "    datasets_validos.append('Pepper')\n",
        "\n",
        "if len(datasets_validos) > 0:\n",
        "    print(f\"\\nâœ… DATASETS BINÃRIOS CARREGADOS: {', '.join(datasets_validos)}\")\n",
        "else:\n",
        "    print(\"\\nâŒ ERRO: Nenhum dataset foi carregado com sucesso!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== CRIANDO GERADORES BINÃRIOS OTIMIZADOS ===\n",
            "Found 11213 validated image filenames belonging to 2 classes.\n",
            "Found 2396 validated image filenames belonging to 2 classes.\n",
            "Found 2402 validated image filenames belonging to 2 classes.\n",
            "Found 1507 validated image filenames belonging to 2 classes.\n",
            "Found 322 validated image filenames belonging to 2 classes.\n",
            "Found 323 validated image filenames belonging to 2 classes.\n",
            "Found 1732 validated image filenames belonging to 2 classes.\n",
            "Found 371 validated image filenames belonging to 2 classes.\n",
            "Found 372 validated image filenames belonging to 2 classes.\n",
            "âœ… Geradores criados com class_mode='binary'\n",
            "\n",
            "=== CRIANDO MODELOS BINÃRIOS OTIMIZADOS ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1751658047.715561   91588 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4047 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Modelo binÃ¡rio Tomato: 24,136,961 parÃ¢metros\n",
            "âœ… Modelo binÃ¡rio Potato: 24,136,961 parÃ¢metros\n",
            "âœ… Modelo binÃ¡rio Pepper: 24,136,961 parÃ¢metros\n",
            "\n",
            "=== CALCULANDO CLASS WEIGHTS ===\n",
            "   Class weights: Healthy=5.033, Unhealthy=0.555\n",
            "   Class weights: Healthy=7.108, Unhealthy=0.538\n",
            "   Class weights: Healthy=0.838, Unhealthy=1.241\n"
          ]
        }
      ],
      "source": [
        "# 2. ARQUITETURA E TREINAMENTO OTIMIZADO\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def criar_classificao_binaria(dataset, config):\n",
        "    \"\"\"Cria geradores otimizados para classificaÃ§Ã£o binÃ¡ria\"\"\"\n",
        "    \n",
        "    # Data augmentation para generalizaÃ§Ã£o\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=30,\n",
        "        width_shift_range=0.3,\n",
        "        height_shift_range=0.3,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        zoom_range=0.3,\n",
        "        brightness_range=[0.7, 1.3],\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "    \n",
        "    val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    \n",
        "    # DataFrames\n",
        "    train_df = pd.DataFrame({'filename': dataset['train']['X'], 'class': dataset['train']['y']})\n",
        "    val_df = pd.DataFrame({'filename': dataset['val']['X'], 'class': dataset['val']['y']})\n",
        "    test_df = pd.DataFrame({'filename': dataset['test']['X'], 'class': dataset['test']['y']})\n",
        "    \n",
        "    # Geradores binÃ¡rios\n",
        "    train_gen = train_datagen.flow_from_dataframe(\n",
        "        train_df, x_col='filename', y_col='class',\n",
        "        target_size=(config['img_height'], config['img_width']),\n",
        "        batch_size=config['batch_size'],\n",
        "        class_mode='binary', shuffle=True, seed=42\n",
        "    )\n",
        "    \n",
        "    val_gen = val_test_datagen.flow_from_dataframe(\n",
        "        val_df, x_col='filename', y_col='class',\n",
        "        target_size=(config['img_height'], config['img_width']),\n",
        "        batch_size=config['batch_size'],\n",
        "        class_mode='binary', shuffle=False, seed=42\n",
        "    )\n",
        "    \n",
        "    test_gen = val_test_datagen.flow_from_dataframe(\n",
        "        test_df, x_col='filename', y_col='class',\n",
        "        target_size=(config['img_height'], config['img_width']),\n",
        "        batch_size=config['batch_size'],\n",
        "        class_mode='binary', shuffle=False, seed=42\n",
        "    )\n",
        "    \n",
        "    return train_gen, val_gen, test_gen\n",
        "\n",
        "def criar_modelo(especie_nome):\n",
        "    \"\"\"Cria modelo de classificaÃ§Ã£o binÃ¡ria\"\"\"\n",
        "    base_model = ResNet50(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(224, 224, 3)\n",
        "    )\n",
        "    \n",
        "    # Descongelar Ãºltimas camadas\n",
        "    base_model.trainable = True\n",
        "    for layer in base_model.layers[:-15]:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    # Arquitetura otimizada para classificaÃ§Ã£o binÃ¡ria\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "    x = Dropout(0.6)(x)\n",
        "    x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    \n",
        "    # SaÃ­da binÃ¡ria com sigmoid\n",
        "    predictions = Dense(1, activation='sigmoid', name=f'output_{especie_nome}')(x)\n",
        "    \n",
        "    modelo = Model(inputs=base_model.input, outputs=predictions)\n",
        "    \n",
        "    print(f\"âœ… Modelo binÃ¡rio {especie_nome}: {modelo.count_params():,} parÃ¢metros\")\n",
        "    return modelo\n",
        "\n",
        "def calcular_class_weights(dataset):\n",
        "    \"\"\"Calcula class weights balanceados\"\"\"\n",
        "    healthy_count = sum(1 for label in dataset['train']['y'] if label == 'healthy')\n",
        "    unhealthy_count = len(dataset['train']['y']) - healthy_count\n",
        "    \n",
        "    total = len(dataset['train']['y'])\n",
        "    weight_healthy = total / (2 * healthy_count)\n",
        "    weight_unhealthy = total / (2 * unhealthy_count)\n",
        "    \n",
        "    class_weights = {0: weight_healthy, 1: weight_unhealthy}  # 0=healthy, 1=unhealthy\n",
        "    \n",
        "    print(f\"   Class weights: Healthy={weight_healthy:.3f}, Unhealthy={weight_unhealthy:.3f}\")\n",
        "    return class_weights\n",
        "\n",
        "# Criar geradores\n",
        "print(\"=== CRIANDO GERADORES BINÃRIOS OTIMIZADOS ===\")\n",
        "train_gen_tomato, val_gen_tomato, test_gen_tomato = criar_classificao_binaria(dataset_tomato, config)\n",
        "train_gen_potato, val_gen_potato, test_gen_potato = criar_classificao_binaria(dataset_potato, config)\n",
        "train_gen_pepper, val_gen_pepper, test_gen_pepper = criar_classificao_binaria(dataset_pepper, config)\n",
        "\n",
        "print(f\"âœ… Geradores criados com class_mode='binary'\")\n",
        "\n",
        "# Criar modelos\n",
        "print(\"\\n=== CRIANDO MODELOS BINÃRIOS OTIMIZADOS ===\")\n",
        "modelo_tomato = criar_modelo('Tomato')\n",
        "modelo_potato = criar_modelo('Potato')\n",
        "modelo_pepper = criar_modelo('Pepper')\n",
        "\n",
        "# Calcular class weights\n",
        "print(\"\\n=== CALCULANDO CLASS WEIGHTS ===\")\n",
        "cw_tomato = calcular_class_weights(dataset_tomato)\n",
        "cw_potato = calcular_class_weights(dataset_potato)\n",
        "cw_pepper = calcular_class_weights(dataset_pepper)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== TREINAMENTO DOS MODELOS BINÃRIOS ===\n",
            "\n",
            "ðŸš€ Treinando Tomato...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/gustavo/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1751658064.893937   91725 service.cc:152] XLA service 0x782368001cf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1751658064.894102   91725 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
            "2025-07-04 16:41:05.472271: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1751658067.491434   91725 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
            "2025-07-04 16:41:12.010729: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.165 = (f32[32,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,56,56]{3,2,1,0} %bitcast.14083, f32[64,64,3,3]{3,2,1,0} %bitcast.14090, f32[64]{0} %bitcast.14092), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 16:41:12.548649: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.175 = (f32[32,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,28,28]{3,2,1,0} %bitcast.14488, f32[128,128,3,3]{3,2,1,0} %bitcast.14495, f32[128]{0} %bitcast.14497), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv3_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 16:41:13.077604: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.188 = (f32[32,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,256,14,14]{3,2,1,0} %bitcast.15016, f32[256,256,3,3]{3,2,1,0} %bitcast.15023, f32[256]{0} %bitcast.15025), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv4_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 16:41:13.606642: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.207 = (f32[32,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,512,7,7]{3,2,1,0} %bitcast.15790, f32[512,512,3,3]{3,2,1,0} %bitcast.15797, f32[512]{0} %bitcast.15799), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv5_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "I0000 00:00:1751658079.018848   91725 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 32/351\u001b[0m \u001b[32mâ”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1:58\u001b[0m 370ms/step - accuracy: 0.7624 - loss: 1.6361"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-04 16:41:33.329343: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.165 = (f32[13,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[13,64,56,56]{3,2,1,0} %bitcast.14083, f32[64,64,3,3]{3,2,1,0} %bitcast.14090, f32[64]{0} %bitcast.14092), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 16:41:33.609727: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.175 = (f32[13,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[13,128,28,28]{3,2,1,0} %bitcast.14488, f32[128,128,3,3]{3,2,1,0} %bitcast.14495, f32[128]{0} %bitcast.14497), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv3_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 16:41:33.961813: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.188 = (f32[13,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[13,256,14,14]{3,2,1,0} %bitcast.15016, f32[256,256,3,3]{3,2,1,0} %bitcast.15023, f32[256]{0} %bitcast.15025), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv4_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 16:41:34.297160: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.207 = (f32[13,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[13,512,7,7]{3,2,1,0} %bitcast.15790, f32[512,512,3,3]{3,2,1,0} %bitcast.15797, f32[512]{0} %bitcast.15799), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv5_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.7519 - loss: 1.3425"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-04 16:43:26.339048: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.162 = (f32[28,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[28,64,56,56]{3,2,1,0} %bitcast.4834, f32[64,64,3,3]{3,2,1,0} %bitcast.4841, f32[64]{0} %bitcast.4843), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 16:43:26.719547: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.172 = (f32[28,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[28,128,28,28]{3,2,1,0} %bitcast.5239, f32[128,128,3,3]{3,2,1,0} %bitcast.5246, f32[128]{0} %bitcast.5248), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv3_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 16:43:27.150188: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.185 = (f32[28,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[28,256,14,14]{3,2,1,0} %bitcast.5767, f32[256,256,3,3]{3,2,1,0} %bitcast.5774, f32[256]{0} %bitcast.5776), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv4_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 16:43:27.577535: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.204 = (f32[28,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[28,512,7,7]{3,2,1,0} %bitcast.6541, f32[512,512,3,3]{3,2,1,0} %bitcast.6548, f32[512]{0} %bitcast.6550), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv5_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 374ms/step - accuracy: 0.7519 - loss: 1.3421 - val_accuracy: 0.7350 - val_loss: 1.0823 - learning_rate: 1.0000e-04\n",
            "Epoch 2/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.7881 - loss: 1.0136"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 284ms/step - accuracy: 0.7881 - loss: 1.0136 - val_accuracy: 0.7600 - val_loss: 1.0321 - learning_rate: 1.0000e-04\n",
            "Epoch 3/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 277ms/step - accuracy: 0.8140 - loss: 0.9601 - val_accuracy: 0.7008 - val_loss: 1.1651 - learning_rate: 1.0000e-04\n",
            "Epoch 4/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.8224 - loss: 0.8919"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 283ms/step - accuracy: 0.8224 - loss: 0.8919 - val_accuracy: 0.8819 - val_loss: 0.7567 - learning_rate: 1.0000e-04\n",
            "Epoch 5/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 271ms/step - accuracy: 0.8266 - loss: 0.8906 - val_accuracy: 0.8418 - val_loss: 0.8384 - learning_rate: 1.0000e-04\n",
            "Epoch 6/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.8393 - loss: 0.8378"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 271ms/step - accuracy: 0.8393 - loss: 0.8378 - val_accuracy: 0.9416 - val_loss: 0.6425 - learning_rate: 1.0000e-04\n",
            "Epoch 7/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 270ms/step - accuracy: 0.8337 - loss: 0.8163 - val_accuracy: 0.6874 - val_loss: 1.2138 - learning_rate: 1.0000e-04\n",
            "Epoch 8/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 265ms/step - accuracy: 0.8570 - loss: 0.7876 - val_accuracy: 0.6302 - val_loss: 1.2344 - learning_rate: 1.0000e-04\n",
            "Epoch 9/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 270ms/step - accuracy: 0.8537 - loss: 0.7458 - val_accuracy: 0.8894 - val_loss: 0.7024 - learning_rate: 1.0000e-04\n",
            "Epoch 10/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.8647 - loss: 0.7314"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 286ms/step - accuracy: 0.8647 - loss: 0.7314 - val_accuracy: 0.9491 - val_loss: 0.8514 - learning_rate: 1.0000e-04\n",
            "Epoch 11/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 269ms/step - accuracy: 0.8508 - loss: 0.7207 - val_accuracy: 0.5351 - val_loss: 1.8211 - learning_rate: 1.0000e-04\n",
            "Epoch 12/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 296ms/step - accuracy: 0.8579 - loss: 0.7108 - val_accuracy: 0.8210 - val_loss: 0.7746 - learning_rate: 1.0000e-04\n",
            "Epoch 13/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 275ms/step - accuracy: 0.8663 - loss: 0.6704 - val_accuracy: 0.3502 - val_loss: 1.9857 - learning_rate: 3.0000e-05\n",
            "Epoch 14/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 276ms/step - accuracy: 0.8862 - loss: 0.6262 - val_accuracy: 0.6215 - val_loss: 1.2774 - learning_rate: 3.0000e-05\n",
            "Epoch 15/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 266ms/step - accuracy: 0.8886 - loss: 0.6415 - val_accuracy: 0.6903 - val_loss: 1.0694 - learning_rate: 3.0000e-05\n",
            "Epoch 16/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 280ms/step - accuracy: 0.8818 - loss: 0.6407 - val_accuracy: 0.7008 - val_loss: 1.0488 - learning_rate: 3.0000e-05\n",
            "Epoch 17/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 277ms/step - accuracy: 0.8912 - loss: 0.6123 - val_accuracy: 0.7250 - val_loss: 0.9853 - learning_rate: 3.0000e-05\n",
            "Epoch 18/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 273ms/step - accuracy: 0.8943 - loss: 0.5953 - val_accuracy: 0.8911 - val_loss: 0.5997 - learning_rate: 3.0000e-05\n",
            "Epoch 19/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 279ms/step - accuracy: 0.8903 - loss: 0.5931 - val_accuracy: 0.5710 - val_loss: 1.4373 - learning_rate: 3.0000e-05\n",
            "Epoch 20/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 290ms/step - accuracy: 0.9043 - loss: 0.5606 - val_accuracy: 0.8568 - val_loss: 0.6698 - learning_rate: 3.0000e-05\n",
            "Epoch 21/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 294ms/step - accuracy: 0.9052 - loss: 0.5599 - val_accuracy: 0.8402 - val_loss: 0.7393 - learning_rate: 3.0000e-05\n",
            "Epoch 22/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 308ms/step - accuracy: 0.8993 - loss: 0.5504 - val_accuracy: 0.5977 - val_loss: 1.3277 - learning_rate: 3.0000e-05\n",
            "Epoch 23/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 309ms/step - accuracy: 0.8995 - loss: 0.5592 - val_accuracy: 0.6106 - val_loss: 1.3679 - learning_rate: 3.0000e-05\n",
            "Epoch 24/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 296ms/step - accuracy: 0.9011 - loss: 0.5312 - val_accuracy: 0.7487 - val_loss: 0.9310 - learning_rate: 3.0000e-05\n",
            "Epoch 25/40\n",
            "\u001b[1m351/351\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 268ms/step - accuracy: 0.9035 - loss: 0.5302 - val_accuracy: 0.4967 - val_loss: 1.7694 - learning_rate: 9.0000e-06\n",
            "âœ… Tomato concluÃ­do! Melhor accuracy: 0.9491\n",
            "\n",
            "ðŸš€ Treinando Potato...\n",
            "Epoch 1/40\n",
            "\u001b[1m 2/48\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5703 - loss: 1.5237  "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-04 17:23:20.511479: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.175 = (f32[3,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[3,128,28,28]{3,2,1,0} %bitcast.14488, f32[128,128,3,3]{3,2,1,0} %bitcast.14495, f32[128]{0} %bitcast.14497), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv3_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:23:20.725314: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.188 = (f32[3,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[3,256,14,14]{3,2,1,0} %bitcast.15016, f32[256,256,3,3]{3,2,1,0} %bitcast.15023, f32[256]{0} %bitcast.15025), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv4_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:23:20.969040: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.207 = (f32[3,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[3,512,7,7]{3,2,1,0} %bitcast.15790, f32[512,512,3,3]{3,2,1,0} %bitcast.15797, f32[512]{0} %bitcast.15799), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv5_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.5972 - loss: 1.6591"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-04 17:23:41.166511: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.172 = (f32[2,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[2,128,28,28]{3,2,1,0} %bitcast.5241, f32[128,128,3,3]{3,2,1,0} %bitcast.5248, f32[128]{0} %bitcast.5250), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv3_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:23:41.413771: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.185 = (f32[2,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[2,256,14,14]{3,2,1,0} %bitcast.5769, f32[256,256,3,3]{3,2,1,0} %bitcast.5776, f32[256]{0} %bitcast.5778), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv4_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:23:41.621579: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.204 = (f32[2,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[2,512,7,7]{3,2,1,0} %bitcast.6543, f32[512,512,3,3]{3,2,1,0} %bitcast.6550, f32[512]{0} %bitcast.6552), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv5_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 602ms/step - accuracy: 0.5976 - loss: 1.6578 - val_accuracy: 0.0714 - val_loss: 1.3178 - learning_rate: 1.0000e-04\n",
            "Epoch 2/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.6073 - loss: 1.3944"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 304ms/step - accuracy: 0.6073 - loss: 1.3951 - val_accuracy: 0.9286 - val_loss: 1.1882 - learning_rate: 1.0000e-04\n",
            "Epoch 3/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 266ms/step - accuracy: 0.5881 - loss: 1.4069 - val_accuracy: 0.4503 - val_loss: 1.2599 - learning_rate: 1.0000e-04\n",
            "Epoch 4/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 271ms/step - accuracy: 0.6040 - loss: 1.3787 - val_accuracy: 0.9224 - val_loss: 1.0963 - learning_rate: 1.0000e-04\n",
            "Epoch 5/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 261ms/step - accuracy: 0.5943 - loss: 1.4672 - val_accuracy: 0.9255 - val_loss: 0.9806 - learning_rate: 1.0000e-04\n",
            "Epoch 6/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 271ms/step - accuracy: 0.6216 - loss: 1.3126 - val_accuracy: 0.7019 - val_loss: 1.1101 - learning_rate: 1.0000e-04\n",
            "Epoch 7/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 288ms/step - accuracy: 0.6093 - loss: 1.3625 - val_accuracy: 0.7857 - val_loss: 1.0915 - learning_rate: 1.0000e-04\n",
            "Epoch 8/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 281ms/step - accuracy: 0.6338 - loss: 1.4514 - val_accuracy: 0.8478 - val_loss: 0.9867 - learning_rate: 1.0000e-04\n",
            "Epoch 9/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 276ms/step - accuracy: 0.6695 - loss: 1.2951 - val_accuracy: 0.8416 - val_loss: 0.9388 - learning_rate: 1.0000e-04\n",
            "Epoch 10/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 262ms/step - accuracy: 0.6733 - loss: 1.2971 - val_accuracy: 0.9099 - val_loss: 0.8585 - learning_rate: 1.0000e-04\n",
            "Epoch 11/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 295ms/step - accuracy: 0.6195 - loss: 1.2532 - val_accuracy: 0.9224 - val_loss: 0.8096 - learning_rate: 1.0000e-04\n",
            "Epoch 12/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 267ms/step - accuracy: 0.6585 - loss: 1.2434 - val_accuracy: 0.9255 - val_loss: 0.7607 - learning_rate: 1.0000e-04\n",
            "Epoch 13/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 272ms/step - accuracy: 0.6428 - loss: 1.1595 - val_accuracy: 0.8168 - val_loss: 0.9568 - learning_rate: 1.0000e-04\n",
            "Epoch 14/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 271ms/step - accuracy: 0.6875 - loss: 1.1785 - val_accuracy: 0.5404 - val_loss: 1.3784 - learning_rate: 1.0000e-04\n",
            "Epoch 15/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 262ms/step - accuracy: 0.6623 - loss: 1.1546 - val_accuracy: 0.7391 - val_loss: 1.0327 - learning_rate: 1.0000e-04\n",
            "Epoch 16/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 286ms/step - accuracy: 0.6585 - loss: 1.1083 - val_accuracy: 0.9037 - val_loss: 0.8134 - learning_rate: 1.0000e-04\n",
            "Epoch 17/40\n",
            "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 273ms/step - accuracy: 0.6899 - loss: 1.2261 - val_accuracy: 0.4348 - val_loss: 1.5789 - learning_rate: 1.0000e-04\n",
            "âœ… Potato concluÃ­do! Melhor accuracy: 0.9286\n",
            "\n",
            "ðŸš€ Treinando Pepper...\n",
            "Epoch 1/40\n",
            "\u001b[1m16/55\u001b[0m \u001b[32mâ”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m11s\u001b[0m 304ms/step - accuracy: 0.5177 - loss: 1.5555"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-04 17:27:39.478855: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.165 = (f32[4,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,64,56,56]{3,2,1,0} %bitcast.14083, f32[64,64,3,3]{3,2,1,0} %bitcast.14090, f32[64]{0} %bitcast.14092), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv2_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:27:39.713344: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.175 = (f32[4,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,128,28,28]{3,2,1,0} %bitcast.14488, f32[128,128,3,3]{3,2,1,0} %bitcast.14495, f32[128]{0} %bitcast.14497), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv3_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:27:39.945101: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.188 = (f32[4,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,256,14,14]{3,2,1,0} %bitcast.15016, f32[256,256,3,3]{3,2,1,0} %bitcast.15023, f32[256]{0} %bitcast.15025), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv4_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:27:40.201681: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.207 = (f32[4,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,512,7,7]{3,2,1,0} %bitcast.15790, f32[512,512,3,3]{3,2,1,0} %bitcast.15797, f32[512]{0} %bitcast.15799), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv5_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.5351 - loss: 1.5450"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-04 17:27:57.722303: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.162 = (f32[19,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[19,64,56,56]{3,2,1,0} %bitcast.4834, f32[64,64,3,3]{3,2,1,0} %bitcast.4841, f32[64]{0} %bitcast.4843), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv2_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:27:57.996689: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.172 = (f32[19,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[19,128,28,28]{3,2,1,0} %bitcast.5239, f32[128,128,3,3]{3,2,1,0} %bitcast.5246, f32[128]{0} %bitcast.5248), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv3_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:27:58.292243: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.185 = (f32[19,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[19,256,14,14]{3,2,1,0} %bitcast.5767, f32[256,256,3,3]{3,2,1,0} %bitcast.5774, f32[256]{0} %bitcast.5776), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv4_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:27:58.588142: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.204 = (f32[19,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[19,512,7,7]{3,2,1,0} %bitcast.6541, f32[512,512,3,3]{3,2,1,0} %bitcast.6548, f32[512]{0} %bitcast.6550), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv5_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 589ms/step - accuracy: 0.5357 - loss: 1.5438 - val_accuracy: 0.4016 - val_loss: 1.4879 - learning_rate: 1.0000e-04\n",
            "Epoch 2/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 275ms/step - accuracy: 0.6005 - loss: 1.3824 - val_accuracy: 0.4016 - val_loss: 1.3145 - learning_rate: 1.0000e-04\n",
            "Epoch 3/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.6293 - loss: 1.3334"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 290ms/step - accuracy: 0.6292 - loss: 1.3336 - val_accuracy: 0.7332 - val_loss: 1.1875 - learning_rate: 1.0000e-04\n",
            "Epoch 4/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 280ms/step - accuracy: 0.6192 - loss: 1.3196 - val_accuracy: 0.6334 - val_loss: 1.1955 - learning_rate: 1.0000e-04\n",
            "Epoch 5/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 259ms/step - accuracy: 0.6301 - loss: 1.2981 - val_accuracy: 0.5714 - val_loss: 1.1953 - learning_rate: 1.0000e-04\n",
            "Epoch 6/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 278ms/step - accuracy: 0.6603 - loss: 1.2376 - val_accuracy: 0.6307 - val_loss: 1.1819 - learning_rate: 1.0000e-04\n",
            "Epoch 7/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 257ms/step - accuracy: 0.6726 - loss: 1.1947 - val_accuracy: 0.7332 - val_loss: 1.1466 - learning_rate: 1.0000e-04\n",
            "Epoch 8/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 281ms/step - accuracy: 0.6529 - loss: 1.2193 - val_accuracy: 0.6361 - val_loss: 1.1533 - learning_rate: 1.0000e-04\n",
            "Epoch 9/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.6830 - loss: 1.1827"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 312ms/step - accuracy: 0.6829 - loss: 1.1828 - val_accuracy: 0.7736 - val_loss: 1.1047 - learning_rate: 1.0000e-04\n",
            "Epoch 10/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 278ms/step - accuracy: 0.6968 - loss: 1.1742 - val_accuracy: 0.6900 - val_loss: 1.1325 - learning_rate: 1.0000e-04\n",
            "Epoch 11/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 273ms/step - accuracy: 0.6877 - loss: 1.1415 - val_accuracy: 0.7520 - val_loss: 1.0408 - learning_rate: 1.0000e-04\n",
            "Epoch 12/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 273ms/step - accuracy: 0.6690 - loss: 1.1599 - val_accuracy: 0.7385 - val_loss: 1.0499 - learning_rate: 1.0000e-04\n",
            "Epoch 13/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 261ms/step - accuracy: 0.7073 - loss: 1.1185 - val_accuracy: 0.7278 - val_loss: 1.0655 - learning_rate: 1.0000e-04\n",
            "Epoch 14/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 260ms/step - accuracy: 0.6811 - loss: 1.1507 - val_accuracy: 0.7736 - val_loss: 1.0069 - learning_rate: 1.0000e-04\n",
            "Epoch 15/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 261ms/step - accuracy: 0.6953 - loss: 1.1348 - val_accuracy: 0.7736 - val_loss: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 16/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 251ms/step - accuracy: 0.7022 - loss: 1.1031 - val_accuracy: 0.7466 - val_loss: 1.0407 - learning_rate: 1.0000e-04\n",
            "Epoch 17/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 267ms/step - accuracy: 0.7033 - loss: 1.1067 - val_accuracy: 0.6927 - val_loss: 1.1765 - learning_rate: 1.0000e-04\n",
            "Epoch 18/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 255ms/step - accuracy: 0.6914 - loss: 1.1016 - val_accuracy: 0.7466 - val_loss: 1.0294 - learning_rate: 1.0000e-04\n",
            "Epoch 19/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 269ms/step - accuracy: 0.6971 - loss: 1.1059 - val_accuracy: 0.7682 - val_loss: 1.0199 - learning_rate: 1.0000e-04\n",
            "Epoch 20/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 256ms/step - accuracy: 0.6907 - loss: 1.1185 - val_accuracy: 0.6442 - val_loss: 1.2395 - learning_rate: 1.0000e-04\n",
            "Epoch 21/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.7128 - loss: 1.0910"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 270ms/step - accuracy: 0.7129 - loss: 1.0908 - val_accuracy: 0.7871 - val_loss: 0.9561 - learning_rate: 1.0000e-04\n",
            "Epoch 22/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 258ms/step - accuracy: 0.7249 - loss: 1.0676 - val_accuracy: 0.7628 - val_loss: 0.9912 - learning_rate: 1.0000e-04\n",
            "Epoch 23/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 261ms/step - accuracy: 0.7021 - loss: 1.0956 - val_accuracy: 0.7844 - val_loss: 0.9656 - learning_rate: 1.0000e-04\n",
            "Epoch 24/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 266ms/step - accuracy: 0.6967 - loss: 1.0775 - val_accuracy: 0.7601 - val_loss: 0.9722 - learning_rate: 1.0000e-04\n",
            "Epoch 25/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 264ms/step - accuracy: 0.7300 - loss: 1.0491 - val_accuracy: 0.7763 - val_loss: 0.9466 - learning_rate: 1.0000e-04\n",
            "Epoch 26/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 268ms/step - accuracy: 0.7484 - loss: 1.0519 - val_accuracy: 0.7493 - val_loss: 0.9882 - learning_rate: 1.0000e-04\n",
            "Epoch 27/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 253ms/step - accuracy: 0.7271 - loss: 1.0394 - val_accuracy: 0.7763 - val_loss: 0.9859 - learning_rate: 1.0000e-04\n",
            "Epoch 28/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.7187 - loss: 1.0539"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 281ms/step - accuracy: 0.7187 - loss: 1.0540 - val_accuracy: 0.7951 - val_loss: 0.9396 - learning_rate: 1.0000e-04\n",
            "Epoch 29/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.7546 - loss: 1.0255"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 271ms/step - accuracy: 0.7544 - loss: 1.0257 - val_accuracy: 0.8005 - val_loss: 0.9312 - learning_rate: 1.0000e-04\n",
            "Epoch 30/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 272ms/step - accuracy: 0.7296 - loss: 1.0307 - val_accuracy: 0.7709 - val_loss: 0.9405 - learning_rate: 1.0000e-04\n",
            "Epoch 31/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 261ms/step - accuracy: 0.7530 - loss: 1.0153 - val_accuracy: 0.7089 - val_loss: 1.0445 - learning_rate: 1.0000e-04\n",
            "Epoch 32/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 259ms/step - accuracy: 0.7240 - loss: 1.0455 - val_accuracy: 0.7817 - val_loss: 0.9333 - learning_rate: 1.0000e-04\n",
            "Epoch 33/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 270ms/step - accuracy: 0.7157 - loss: 1.0295 - val_accuracy: 0.7790 - val_loss: 0.9258 - learning_rate: 1.0000e-04\n",
            "Epoch 34/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 260ms/step - accuracy: 0.7453 - loss: 1.0239 - val_accuracy: 0.6119 - val_loss: 1.2557 - learning_rate: 1.0000e-04\n",
            "Epoch 35/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.7446 - loss: 1.0171"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 285ms/step - accuracy: 0.7446 - loss: 1.0169 - val_accuracy: 0.8113 - val_loss: 0.8881 - learning_rate: 1.0000e-04\n",
            "Epoch 36/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 265ms/step - accuracy: 0.7469 - loss: 1.0027 - val_accuracy: 0.6765 - val_loss: 1.3188 - learning_rate: 1.0000e-04\n",
            "Epoch 37/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 270ms/step - accuracy: 0.7502 - loss: 0.9836 - val_accuracy: 0.6981 - val_loss: 0.9937 - learning_rate: 1.0000e-04\n",
            "Epoch 38/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 252ms/step - accuracy: 0.7251 - loss: 1.0074 - val_accuracy: 0.7601 - val_loss: 0.9585 - learning_rate: 1.0000e-04\n",
            "Epoch 39/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 274ms/step - accuracy: 0.7577 - loss: 0.9661 - val_accuracy: 0.6307 - val_loss: 1.2445 - learning_rate: 1.0000e-04\n",
            "Epoch 40/40\n",
            "\u001b[1m55/55\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 250ms/step - accuracy: 0.7387 - loss: 0.9854 - val_accuracy: 0.7116 - val_loss: 1.0102 - learning_rate: 1.0000e-04\n",
            "âœ… Pepper concluÃ­do! Melhor accuracy: 0.8113\n",
            "\n",
            "ðŸŽ¯ TODOS OS MODELOS TREINADOS COM SUCESSO!\n"
          ]
        }
      ],
      "source": [
        "# 3. TREINAMENTO OTIMIZADO COM CLASS WEIGHTS\n",
        "def treinar_modelo_binario(modelo, especie, train_gen, val_gen, class_weights):\n",
        "    \"\"\"Treina modelo de classificaÃ§Ã£o binÃ¡ria com class weights\"\"\"\n",
        "    print(f\"\\nðŸš€ Treinando {especie}...\")\n",
        "    \n",
        "    # CompilaÃ§Ã£o\n",
        "    modelo.compile(\n",
        "        optimizer=Adam(learning_rate=0.0001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    # Callback\n",
        "    callbacks = [\n",
        "        EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=15,\n",
        "            restore_best_weights=True,\n",
        "            min_delta=0.001\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.3,\n",
        "            patience=6,\n",
        "            min_lr=1e-8\n",
        "        ),\n",
        "        ModelCheckpoint(\n",
        "            filepath=f'modelos_salvos/especialistas/modelo_binario_{especie.lower()}.h5',\n",
        "            monitor='val_accuracy',\n",
        "            save_best_only=True\n",
        "        )\n",
        "    ]\n",
        "    \n",
        "    # Treinamento\n",
        "    history = modelo.fit(\n",
        "        train_gen,\n",
        "        epochs=40,\n",
        "        validation_data=val_gen,\n",
        "        class_weight=class_weights,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "    \n",
        "    final_accuracy = max(history.history['val_accuracy'])\n",
        "    print(f\"âœ… {especie} concluÃ­do! Melhor accuracy: {final_accuracy:.4f}\")\n",
        "    \n",
        "    return history\n",
        "\n",
        "# Treinar todos os modelos\n",
        "os.makedirs('modelos_salvos', exist_ok=True)\n",
        "\n",
        "print(\"=== TREINAMENTO DOS MODELOS BINÃRIOS ===\")\n",
        "history_tomato = treinar_modelo_binario(modelo_tomato, 'Tomato', train_gen_tomato, val_gen_tomato, cw_tomato)\n",
        "history_potato = treinar_modelo_binario(modelo_potato, 'Potato', train_gen_potato, val_gen_potato, cw_potato)\n",
        "history_pepper = treinar_modelo_binario(modelo_pepper, 'Pepper', train_gen_pepper, val_gen_pepper, cw_pepper)\n",
        "\n",
        "print(\"\\nðŸŽ¯ TODOS OS MODELOS TREINADOS COM SUCESSO!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== AVALIAÃ‡ÃƒO FINAL DOS MODELOS BINÃRIOS ===\n",
            "\n",
            "ðŸ“Š Avaliando Tomato...\n",
            "   ðŸŽ¯ Accuracy: 0.9450\n",
            "   ðŸŽ¯ AUC-ROC: 0.8940\n",
            "   ðŸŽ¯ Recall: 0.9894\n",
            "   ðŸŽ¯ Precision: 0.9515\n",
            "   ðŸŽ¯ F1-Score: 0.9701\n",
            "   Matriz: [[130, 109], [ 23, 2140]]\n",
            "\n",
            "   Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Healthy       0.85      0.54      0.66       239\n",
            "   Unhealthy       0.95      0.99      0.97      2163\n",
            "\n",
            "    accuracy                           0.95      2402\n",
            "   macro avg       0.90      0.77      0.82      2402\n",
            "weighted avg       0.94      0.95      0.94      2402\n",
            "\n",
            "\n",
            "ðŸ“Š Avaliando Potato...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/gustavo/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ðŸŽ¯ Accuracy: 0.9319\n",
            "   ðŸŽ¯ AUC-ROC: 0.7168\n",
            "   ðŸŽ¯ Recall: 0.9933\n",
            "   ðŸŽ¯ Precision: 0.9371\n",
            "   ðŸŽ¯ F1-Score: 0.9644\n",
            "   Matriz: [[  3,  20], [  2, 298]]\n",
            "\n",
            "   Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Healthy       0.60      0.13      0.21        23\n",
            "   Unhealthy       0.94      0.99      0.96       300\n",
            "\n",
            "    accuracy                           0.93       323\n",
            "   macro avg       0.77      0.56      0.59       323\n",
            "weighted avg       0.91      0.93      0.91       323\n",
            "\n",
            "\n",
            "ðŸ“Š Avaliando Pepper...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/gustavo/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "2025-07-04 17:38:08.358691: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.162 = (f32[20,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[20,64,56,56]{3,2,1,0} %bitcast.4595, f32[64,64,3,3]{3,2,1,0} %bitcast.4602, f32[64]{0} %bitcast.4604), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv2_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:38:08.652111: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.172 = (f32[20,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[20,128,28,28]{3,2,1,0} %bitcast.5000, f32[128,128,3,3]{3,2,1,0} %bitcast.5007, f32[128]{0} %bitcast.5009), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv3_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:38:08.971163: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.185 = (f32[20,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[20,256,14,14]{3,2,1,0} %bitcast.5528, f32[256,256,3,3]{3,2,1,0} %bitcast.5535, f32[256]{0} %bitcast.5537), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv4_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-07-04 17:38:09.287110: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.204 = (f32[20,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[20,512,7,7]{3,2,1,0} %bitcast.6302, f32[512,512,3,3]{3,2,1,0} %bitcast.6309, f32[512]{0} %bitcast.6311), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_2_1/conv5_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ðŸŽ¯ Accuracy: 0.8253\n",
            "   ðŸŽ¯ AUC-ROC: 0.8853\n",
            "   ðŸŽ¯ Recall: 0.7467\n",
            "   ðŸŽ¯ Precision: 0.8058\n",
            "   ðŸŽ¯ F1-Score: 0.7751\n",
            "   Matriz: [[195,  27], [ 38, 112]]\n",
            "\n",
            "   Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Healthy       0.84      0.88      0.86       222\n",
            "   Unhealthy       0.81      0.75      0.78       150\n",
            "\n",
            "    accuracy                           0.83       372\n",
            "   macro avg       0.82      0.81      0.82       372\n",
            "weighted avg       0.82      0.83      0.82       372\n",
            "\n",
            "\n",
            "=== COMPARAÃ‡ÃƒO FINAL ===\n",
            "   Tomato: 0.9450 - ðŸŸ¢ EXCELENTE\n",
            "   Potato: 0.9319 - ðŸŸ¢ EXCELENTE\n",
            "   Pepper: 0.8253 - ðŸŸ¡ BOA\n"
          ]
        }
      ],
      "source": [
        "# 4. AVALIAÃ‡ÃƒO DO MODELO\n",
        "from sklearn.metrics import (\n",
        "    classification_report, \n",
        "    accuracy_score, \n",
        "    confusion_matrix, \n",
        "    roc_auc_score, \n",
        "    recall_score, \n",
        "    precision_score, \n",
        "    f1_score\n",
        "    )\n",
        "\n",
        "def avaliar_modelo(modelo, especie, test_gen, dataset_test):\n",
        "    \"\"\"AvaliaÃ§Ã£o completa do modelo de classificaÃ§Ã£o binÃ¡ria\"\"\"\n",
        "    print(f\"\\nðŸ“Š Avaliando {especie}...\")\n",
        "    \n",
        "    test_gen.reset()\n",
        "    \n",
        "    # PrediÃ§Ãµes\n",
        "    predictions_prob = modelo.predict(test_gen, verbose=0)\n",
        "    predictions_class = (predictions_prob > 0.5).astype(int).flatten()\n",
        "    \n",
        "    # Classes verdadeiras\n",
        "    true_classes = [1 if label == 'unhealthy' else 0 for label in dataset_test['y']]\n",
        "    \n",
        "    # MÃ©tricas\n",
        "    accuracy = accuracy_score(true_classes, predictions_class)\n",
        "    auc_score = roc_auc_score(true_classes, predictions_prob)\n",
        "    cm = confusion_matrix(true_classes, predictions_class)\n",
        "    recall = recall_score(true_classes, predictions_class)\n",
        "    precision = precision_score(true_classes, predictions_class)\n",
        "    f1 = f1_score(true_classes, predictions_class)\n",
        "\n",
        "    # MÃ©tricas mÃ©dicas\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    \n",
        "    print(f\"   ðŸŽ¯ Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"   ðŸŽ¯ AUC-ROC: {auc_score:.4f}\")\n",
        "    print(f\"   ðŸŽ¯ Recall: {recall:.4f}\")\n",
        "    print(f\"   ðŸŽ¯ Precision: {precision:.4f}\")\n",
        "    print(f\"   ðŸŽ¯ F1-Score: {f1:.4f}\")\n",
        "\n",
        "    \n",
        "    # Matriz de confusÃ£o\n",
        "    print(f\"   Matriz: [[{tn:3d}, {fp:3d}], [{fn:3d}, {tp:3d}]]\")\n",
        "    \n",
        "    # RelatÃ³rio\n",
        "    print(\"\\n   Classification Report:\")\n",
        "    print(classification_report(true_classes, predictions_class, target_names=['Healthy', 'Unhealthy'], zero_division=0))\n",
        "    \n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'auc_roc': auc_score,\n",
        "        'confusion_matrix': cm,\n",
        "        'recall': recall,\n",
        "        'precision': precision,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "# Avaliar todos os modelos\n",
        "print(\"=== AVALIAÃ‡ÃƒO FINAL DOS MODELOS BINÃRIOS ===\")\n",
        "resultados_tomato = avaliar_modelo(modelo_tomato, 'Tomato', test_gen_tomato, dataset_tomato['test'])\n",
        "resultados_potato = avaliar_modelo(modelo_potato, 'Potato', test_gen_potato, dataset_potato['test'])\n",
        "resultados_pepper = avaliar_modelo(modelo_pepper, 'Pepper', test_gen_pepper, dataset_pepper['test'])\n",
        "\n",
        "# ComparaÃ§Ã£o final\n",
        "print(f\"\\n=== COMPARAÃ‡ÃƒO FINAL ===\")\n",
        "resultados = [\n",
        "    ('Tomato', resultados_tomato),\n",
        "    ('Potato', resultados_potato), \n",
        "    ('Pepper', resultados_pepper)\n",
        "]\n",
        "\n",
        "for especie, resultado in resultados:\n",
        "    qualidade = \"ðŸŸ¢ EXCELENTE\" if resultado['accuracy'] > 0.9 else \"ðŸŸ¡ BOA\" if resultado['accuracy'] > 0.7 else \"ðŸ”´ INSUFICIENTE\"\n",
        "    print(f\"   {especie}: {resultado['accuracy']:.4f} - {qualidade}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SALVANDO MODELOS OTIMIZADOS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Salvar modelos finais\n",
        "print(\"SALVANDO MODELOS OTIMIZADOS\")\n",
        "modelo_tomato.save('modelos_salvos/especialistas/especialista_tomato_binario_final.h5')\n",
        "modelo_potato.save('modelos_salvos/especialistas/especialista_potato_binario_final.h5')\n",
        "modelo_pepper.save('modelos_salvos/especialistas/especialista_pepper_binario_final.h5')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
