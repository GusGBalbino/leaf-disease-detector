{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 23:18:14.565796: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751854694.630642  264921 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751854694.652611  264921 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751854694.757982  264921 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751854694.758021  264921 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751854694.758023  264921 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751854694.758025  264921 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-06 23:18:14.784823: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CARREGANDO MODELOS TREINADOS ===\n",
      "📂 Carregando modelo de espécies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751854699.325984  264921 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4047 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "/home/gustavo/.local/lib/python3.10/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.7.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Modelo de espécies: ['Pepper_bell' 'Potato' 'Tomato']\n",
      "📂 Carregando modelos especialistas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Modelo tomato: carregado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Modelo potato: carregado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Modelo pepper: carregado\n"
     ]
    }
   ],
   "source": [
    "# 1. CARREGAMENTO DOS MODELOS TREINADOS\n",
    "from utils import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurações\n",
    "config = carregar_configuracoes()\n",
    "print(\"=== CARREGANDO MODELOS TREINADOS ===\")\n",
    "\n",
    "# Carregar modelo de classificação de espécies\n",
    "print(\"📂 Carregando modelo de espécies...\")\n",
    "modelo_especies = load_model('modelos_salvos/melhor_modelo_especies_final_otimizado.h5')\n",
    "with open('datasets_processados/label_encoder_especies_modelo.pkl', 'rb') as f:\n",
    "    encoder_especies = pickle.load(f)\n",
    "\n",
    "print(f\"   ✅ Modelo de espécies: {encoder_especies.classes_}\")\n",
    "\n",
    "# Carregar modelos de classificação de saúde\n",
    "print(\"📂 Carregando modelos especialistas...\")\n",
    "modelos_especialistas = {}\n",
    "especies_disponiveis = []\n",
    "\n",
    "for especie in ['tomato', 'potato', 'pepper']:\n",
    "    modelo_path = f'modelos_salvos/especialistas/especialista_{especie}_binario_final.h5'\n",
    "    if os.path.exists(modelo_path):\n",
    "        modelos_especialistas[especie] = load_model(modelo_path)\n",
    "        especies_disponiveis.append(especie)\n",
    "        print(f\"   ✅ Modelo {especie}: carregado\")\n",
    "    else:\n",
    "        print(f\"   ⚠️ Modelo {especie}: não encontrado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pipeline hierárquico implementado!\n",
      "\n",
      "🧪 Testando com: Tomato_Bacterial_spot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1751854742.309154  265008 service.cc:152] XLA service 0x7513c80029d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1751854742.311132  265008 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2025-07-06 23:19:03.302621: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1751854744.992196  265008 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-07-06 23:19:10.227061: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.172 = (f32[1,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,128,28,28]{3,2,1,0} %bitcast.5016, f32[128,128,3,3]{3,2,1,0} %bitcast.5023, f32[128]{0} %bitcast.5025), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv3_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-07-06 23:19:10.480203: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.185 = (f32[1,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,256,14,14]{3,2,1,0} %bitcast.5544, f32[256,256,3,3]{3,2,1,0} %bitcast.5551, f32[256]{0} %bitcast.5553), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv4_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-07-06 23:19:10.665261: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.204 = (f32[1,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,512,7,7]{3,2,1,0} %bitcast.6318, f32[512,512,3,3]{3,2,1,0} %bitcast.6325, f32[512]{0} %bitcast.6327), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv5_block1_2_conv_1/convolution\" source_file=\"/home/gustavo/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "I0000 00:00:1751854752.278471  265008 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Espécie: Tomato (conf: 0.665)\n",
      "   Saúde: unhealthy (conf: 1.000)\n",
      "   Final: Tomato_unhealthy (conf: 0.665)\n"
     ]
    }
   ],
   "source": [
    "# 2. IMPLEMENTAÇÃO DO PIPELINE HIERÁRQUICO\n",
    "def preprocessar_imagem(caminho_imagem, target_size=(224, 224)):\n",
    "    \"\"\"Preprocessa imagem para os modelos\"\"\"\n",
    "    img = image.load_img(caminho_imagem, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = img_array / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "def pipeline_hierarquico(caminho_imagem, modelo_especies, encoder_especies, modelos_especialistas, threshold_confianca=0.5):\n",
    "    \"\"\"\n",
    "    Pipeline completo: Passo 3 (espécie) → Passo 4 (saúde)\n",
    "    \n",
    "    Returns:\n",
    "        dict: {\n",
    "            'especie_predita': str,\n",
    "            'confianca_especie': float,\n",
    "            'saude_predita': str,\n",
    "            'confianca_saude': float,\n",
    "            'resultado_final': str,\n",
    "            'confianca_final': float,\n",
    "            'etapas': dict\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Preprocessar imagem\n",
    "    img_preprocessada = preprocessar_imagem(caminho_imagem)\n",
    "    \n",
    "    #Classificar espécie\n",
    "    pred_especies = modelo_especies.predict(img_preprocessada, verbose=0)\n",
    "    indice_especie = np.argmax(pred_especies)\n",
    "    especie_predita = encoder_especies.inverse_transform([indice_especie])[0]\n",
    "    confianca_especie = np.max(pred_especies)\n",
    "    \n",
    "    # Mapear nome da espécie para o modelo especialista\n",
    "    mapeamento_especies = {\n",
    "        'Tomato': 'tomato',\n",
    "        'Potato': 'potato', \n",
    "        'Pepper_bell': 'pepper'\n",
    "    }\n",
    "    \n",
    "    especie_modelo = mapeamento_especies.get(especie_predita)\n",
    "    \n",
    "    #Classificar saúde\n",
    "    if especie_modelo and especie_modelo in modelos_especialistas:\n",
    "        modelo_especialista = modelos_especialistas[especie_modelo]\n",
    "        pred_saude = modelo_especialista.predict(img_preprocessada, verbose=0)[0][0]\n",
    "        \n",
    "        # Conversão binária: >0.5 = unhealthy, <=0.5 = healthy\n",
    "        if pred_saude > 0.5:\n",
    "            saude_predita = 'unhealthy'\n",
    "            confianca_saude = pred_saude\n",
    "        else:\n",
    "            saude_predita = 'healthy'\n",
    "            confianca_saude = 1 - pred_saude\n",
    "            \n",
    "        # Resultado final combinado\n",
    "        resultado_final = f\"{especie_predita}_{saude_predita}\"\n",
    "        confianca_final = confianca_especie * confianca_saude  # Propagação de incerteza\n",
    "        \n",
    "        sucesso_pipeline = True\n",
    "        \n",
    "    else:\n",
    "        # Modelo especialista não disponível\n",
    "        saude_predita = 'unknown'\n",
    "        confianca_saude = 0.0\n",
    "        resultado_final = f\"{especie_predita}_unknown\"\n",
    "        confianca_final = confianca_especie\n",
    "        sucesso_pipeline = False\n",
    "    \n",
    "    return {\n",
    "        'especie_predita': especie_predita,\n",
    "        'confianca_especie': float(confianca_especie),\n",
    "        'saude_predita': saude_predita,\n",
    "        'confianca_saude': float(confianca_saude),\n",
    "        'resultado_final': resultado_final,\n",
    "        'confianca_final': float(confianca_final),\n",
    "        'sucesso_pipeline': sucesso_pipeline,\n",
    "        'etapas': {\n",
    "            'passo3_especies': {'pred': especie_predita, 'conf': float(confianca_especie)},\n",
    "            'passo4_saude': {'pred': saude_predita, 'conf': float(confianca_saude)}\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"✅ Pipeline hierárquico implementado!\")\n",
    "\n",
    "\n",
    "# Encontrar uma imagem de teste\n",
    "test_image = None\n",
    "for especie in ['Tomato', 'Potato', 'Pepper_bell']:\n",
    "    for classe in config['especialistas'][especie]['classes']:\n",
    "        pasta_classe = os.path.join(config['base_path'], classe)\n",
    "        if os.path.exists(pasta_classe):\n",
    "            images = [f for f in os.listdir(pasta_classe) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            if images:\n",
    "                test_image = os.path.join(pasta_classe, images[0])\n",
    "                test_class = classe\n",
    "                break\n",
    "    if test_image:\n",
    "        break\n",
    "\n",
    "if test_image:\n",
    "    print(f\"\\n🧪 Testando com: {test_class}\")\n",
    "    resultado = pipeline_hierarquico(test_image, modelo_especies, encoder_especies, modelos_especialistas)\n",
    "    print(f\"   Espécie: {resultado['especie_predita']} (conf: {resultado['confianca_especie']:.3f})\")\n",
    "    print(f\"   Saúde: {resultado['saude_predita']} (conf: {resultado['confianca_saude']:.3f})\")\n",
    "    print(f\"   Final: {resultado['resultado_final']} (conf: {resultado['confianca_final']:.3f})\")\n",
    "else:\n",
    "    print(\"⚠️ Nenhuma imagem de teste encontrada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processando Tomato...\n",
      "   ✅ Tomato_Bacterial_spot: 30 imagens selecionadas\n",
      "   ✅ Tomato_Early_blight: 30 imagens selecionadas\n",
      "   ✅ Tomato_Late_blight: 30 imagens selecionadas\n",
      "   ✅ Tomato_Leaf_Mold: 30 imagens selecionadas\n",
      "   ✅ Tomato_Septoria_leaf_spot: 30 imagens selecionadas\n",
      "   ✅ Tomato_Spider_mites_Two_spotted_spider_mite: 30 imagens selecionadas\n",
      "   ✅ Tomato__Target_Spot: 30 imagens selecionadas\n",
      "   ✅ Tomato__Tomato_YellowLeaf__Curl_Virus: 30 imagens selecionadas\n",
      "   ✅ Tomato__Tomato_mosaic_virus: 30 imagens selecionadas\n",
      "   ✅ Tomato_healthy: 30 imagens selecionadas\n",
      "📂 Processando Potato...\n",
      "   ✅ Potato___Early_blight: 30 imagens selecionadas\n",
      "   ✅ Potato___Late_blight: 30 imagens selecionadas\n",
      "   ✅ Potato___healthy: 30 imagens selecionadas\n",
      "📂 Processando Pepper_bell...\n",
      "   ✅ Pepper__bell___Bacterial_spot: 30 imagens selecionadas\n",
      "   ✅ Pepper__bell___healthy: 30 imagens selecionadas\n",
      "\n",
      "📊 CONJUNTO DE TESTE CRIADO:\n",
      "   Total de imagens: 450\n",
      "   Espécies: {'Tomato': 300, 'Potato': 90, 'Pepper_bell': 60}\n",
      "   Saúde: {'unhealthy': 360, 'healthy': 90}\n",
      "\n",
      "💾 Conjunto de teste salvo em: datasets_processados/conjunto_teste_hierarquico.csv\n"
     ]
    }
   ],
   "source": [
    "# 3. CRIAÇÃO DO CONJUNTO DE TESTE HIERÁRQUICO\n",
    "def criar_conjunto_teste_hierarquico(config, n_samples_per_class=50):\n",
    "    \"\"\"\n",
    "    Cria conjunto de teste balanceado para avaliação hierárquica\n",
    "    \"\"\"\n",
    "    \n",
    "    conjunto_teste = []\n",
    "    \n",
    "    for especie, info in config['especialistas'].items():\n",
    "        print(f\"📂 Processando {especie}...\")\n",
    "        \n",
    "        for classe in info['classes']:\n",
    "            pasta_classe = os.path.join(config['base_path'], classe)\n",
    "            \n",
    "            if not os.path.exists(pasta_classe):\n",
    "                print(f\"   ⚠️ Pasta não encontrada: {classe}\")\n",
    "                continue\n",
    "                \n",
    "            # Obter imagens da classe\n",
    "            images = [f for f in os.listdir(pasta_classe) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            \n",
    "            if len(images) == 0:\n",
    "                print(f\"   ⚠️ Nenhuma imagem em: {classe}\")\n",
    "                continue\n",
    "                \n",
    "            # Selecionar amostra aleatória\n",
    "            np.random.seed(42)\n",
    "            n_select = min(n_samples_per_class, len(images))\n",
    "            selected_images = np.random.choice(images, n_select, replace=False)\n",
    "            \n",
    "            # Determinar rótulos\n",
    "            especie_label = especie\n",
    "            saude_label = 'healthy' if 'healthy' in classe.lower() else 'unhealthy'\n",
    "            combined_label = f\"{especie}_{saude_label}\"\n",
    "            \n",
    "            # Adicionar ao conjunto\n",
    "            for img_name in selected_images:\n",
    "                caminho_completo = os.path.join(pasta_classe, img_name)\n",
    "                conjunto_teste.append({\n",
    "                    'caminho': caminho_completo,\n",
    "                    'classe_original': classe,\n",
    "                    'especie_real': especie_label,\n",
    "                    'saude_real': saude_label,\n",
    "                    'combined_real': combined_label\n",
    "                })\n",
    "            \n",
    "            print(f\"   ✅ {classe}: {n_select} imagens selecionadas\")\n",
    "    \n",
    "    # Converter para DataFrame\n",
    "    df_teste = pd.DataFrame(conjunto_teste)\n",
    "    \n",
    "    print(f\"\\n📊 CONJUNTO DE TESTE CRIADO:\")\n",
    "    print(f\"   Total de imagens: {len(df_teste)}\")\n",
    "    print(f\"   Espécies: {df_teste['especie_real'].value_counts().to_dict()}\")\n",
    "    print(f\"   Saúde: {df_teste['saude_real'].value_counts().to_dict()}\")\n",
    "    \n",
    "    return df_teste\n",
    "\n",
    "# Criar conjunto de teste\n",
    "df_teste_hierarquico = criar_conjunto_teste_hierarquico(config, n_samples_per_class=30)\n",
    "\n",
    "# Salvar para reutilização\n",
    "df_teste_hierarquico.to_csv('datasets_processados/conjunto_teste_hierarquico.csv', index=False)\n",
    "print(\"\\n💾 Conjunto de teste salvo em: datasets_processados/conjunto_teste_hierarquico.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Iniciando avaliação completa...\n",
      "   Processando 1/450...\n",
      "   Processando 51/450...\n",
      "   Processando 101/450...\n",
      "   Processando 151/450...\n",
      "   Processando 201/450...\n",
      "   Processando 251/450...\n",
      "   Processando 301/450...\n",
      "   Processando 351/450...\n",
      "   Processando 401/450...\n",
      "\n",
      "💾 Resultados salvos em: datasets_processados/resultados_pipeline_hierarquico.csv\n",
      "\n",
      "✅ Avaliação concluída: 450 predições realizadas\n"
     ]
    }
   ],
   "source": [
    "# 4. AVALIAÇÃO COMPLETA DO PIPELINE HIERÁRQUICO\n",
    "def avaliar_pipeline_hierarquico(df_teste, modelo_especies, encoder_especies, modelos_especialistas):\n",
    "    \"\"\"\n",
    "    Avalia o pipeline hierárquico completo\n",
    "    \"\"\"\n",
    "    \n",
    "    resultados = []\n",
    "    \n",
    "    # Processar cada imagem\n",
    "    for idx, row in df_teste.iterrows():\n",
    "        if idx % 50 == 0:\n",
    "            print(f\"   Processando {idx+1}/{len(df_teste)}...\")\n",
    "            \n",
    "        # Aplicar pipeline hierárquico\n",
    "        resultado = pipeline_hierarquico(\n",
    "            row['caminho'], \n",
    "            modelo_especies, \n",
    "            encoder_especies, \n",
    "            modelos_especialistas\n",
    "        )\n",
    "        \n",
    "        # Adicionar dados reais\n",
    "        resultado['especie_real'] = row['especie_real']\n",
    "        resultado['saude_real'] = row['saude_real']\n",
    "        resultado['combined_real'] = row['combined_real']\n",
    "        resultado['classe_original'] = row['classe_original']\n",
    "        \n",
    "        # Calcular acertos\n",
    "        resultado['acerto_especie'] = resultado['especie_predita'] == resultado['especie_real']\n",
    "        resultado['acerto_saude'] = resultado['saude_predita'] == resultado['saude_real']\n",
    "        resultado['acerto_combined'] = resultado['resultado_final'] == resultado['combined_real']\n",
    "        \n",
    "        resultados.append(resultado)\n",
    "    \n",
    "    # Converter para DataFrame\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "    \n",
    "    return df_resultados\n",
    "\n",
    "# Executar avaliação\n",
    "print(\"🚀 Iniciando avaliação completa...\")\n",
    "df_resultados = avaliar_pipeline_hierarquico(\n",
    "    df_teste_hierarquico, \n",
    "    modelo_especies, \n",
    "    encoder_especies, \n",
    "    modelos_especialistas\n",
    ")\n",
    "\n",
    "# Salvar resultados\n",
    "df_resultados.to_csv('datasets_processados/resultados_pipeline_hierarquico.csv', index=False)\n",
    "print(\"\\n💾 Resultados salvos em: datasets_processados/resultados_pipeline_hierarquico.csv\")\n",
    "\n",
    "print(f\"\\n✅ Avaliação concluída: {len(df_resultados)} predições realizadas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 ACURÁCIAS POR ETAPA:\n",
      "Classificação de espécie: 0.8867 (88.7%)\n",
      "Classificação de saúde: 0.8667 (86.7%)\n",
      "Pipeline completo: 0.7689 (76.9%)\n",
      "\n",
      "🔍 ANÁLISE DE PROPAGAÇÃO:\n",
      "   Acurácia de saúde QUANDO espécie está correta: 0.8672 (86.7%)\n",
      "   Acurácia de saúde QUANDO espécie está incorreta: 0.8627 (86.3%)\n",
      "\n",
      "⚖️ IMPACTO DA PROPAGAÇÃO:\n",
      "   Acurácia teórica (independente): 0.7689\n",
      "   Acurácia real (hierárquica): 0.7689\n",
      "   Impacto da propagação: +0.0000\n",
      "\n",
      "📈 MATRIZES DE CONFUSÃO:\n",
      "\n",
      "🌱 CLASSIFICAÇÃO DE ESPÉCIE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Pepper_bell       0.81      0.92      0.86        60\n",
      "      Potato       0.71      0.93      0.80        90\n",
      "      Tomato       0.99      0.87      0.92       300\n",
      "\n",
      "    accuracy                           0.89       450\n",
      "   macro avg       0.83      0.91      0.86       450\n",
      "weighted avg       0.91      0.89      0.89       450\n",
      "\n",
      "\n",
      "🏥 CLASSIFICAÇÃO DE SAÚDE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     healthy       0.75      0.50      0.60        90\n",
      "   unhealthy       0.88      0.96      0.92       360\n",
      "\n",
      "    accuracy                           0.87       450\n",
      "   macro avg       0.82      0.73      0.76       450\n",
      "weighted avg       0.86      0.87      0.86       450\n",
      "\n",
      "\n",
      "🔬 ANÁLISE POR ESPÉCIE:\n",
      "   Tomato:\n",
      "     Espécie: 0.867 | Saúde: 0.950 | Completo: 0.823\n",
      "   Potato:\n",
      "     Espécie: 0.933 | Saúde: 0.678 | Completo: 0.644\n",
      "   Pepper_bell:\n",
      "     Espécie: 0.917 | Saúde: 0.733 | Completo: 0.683\n",
      "\n",
      "🎯 ANÁLISE DE CONFIANÇA:\n",
      "   Confiança média - Espécie: 0.867\n",
      "   Confiança média - Saúde: 0.845\n",
      "   Confiança média - Final: 0.731\n"
     ]
    }
   ],
   "source": [
    "# 5. ANÁLISE DE PROPAGAÇÃO DE ERROS E MÉTRICAS\n",
    "def analisar_propagacao_erros(df_resultados):\n",
    "    \"\"\"\n",
    "    Analisa como erros se propagam no pipeline hierárquico\n",
    "    \"\"\"\n",
    "    \n",
    "    # Métricas por etapa\n",
    "    acc_especie = df_resultados['acerto_especie'].mean()\n",
    "    acc_saude = df_resultados['acerto_saude'].mean()\n",
    "    acc_combined = df_resultados['acerto_combined'].mean()\n",
    "    \n",
    "    print(\"📊 ACURÁCIAS POR ETAPA:\")\n",
    "    print(f\"Classificação de espécie: {acc_especie:.4f} ({acc_especie*100:.1f}%)\")\n",
    "    print(f\"Classificação de saúde: {acc_saude:.4f} ({acc_saude*100:.1f}%)\")\n",
    "    print(f\"Pipeline completo: {acc_combined:.4f} ({acc_combined*100:.1f}%)\")\n",
    "    \n",
    "    # Análise de propagação de erros\n",
    "    print(f\"\\n🔍 ANÁLISE DE PROPAGAÇÃO:\")\n",
    "    \n",
    "    # Casos onde espécie está correta\n",
    "    correto_especie = df_resultados[df_resultados['acerto_especie'] == True]\n",
    "    if len(correto_especie) > 0:\n",
    "        acc_saude_dado_especie_correta = correto_especie['acerto_saude'].mean()\n",
    "        print(f\"   Acurácia de saúde QUANDO espécie está correta: {acc_saude_dado_especie_correta:.4f} ({acc_saude_dado_especie_correta*100:.1f}%)\")\n",
    "    \n",
    "    # Casos onde espécie está incorreta\n",
    "    incorreto_especie = df_resultados[df_resultados['acerto_especie'] == False]\n",
    "    if len(incorreto_especie) > 0:\n",
    "        acc_saude_dado_especie_incorreta = incorreto_especie['acerto_saude'].mean()\n",
    "        print(f\"   Acurácia de saúde QUANDO espécie está incorreta: {acc_saude_dado_especie_incorreta:.4f} ({acc_saude_dado_especie_incorreta*100:.1f}%)\")\n",
    "    \n",
    "    # Impacto da propagação\n",
    "    acc_teorica = acc_especie * acc_saude_dado_especie_correta if len(correto_especie) > 0 else 0\n",
    "    impacto_propagacao = acc_combined - acc_teorica\n",
    "    \n",
    "    print(f\"\\n⚖️ IMPACTO DA PROPAGAÇÃO:\")\n",
    "    print(f\"   Acurácia teórica (independente): {acc_teorica:.4f}\")\n",
    "    print(f\"   Acurácia real (hierárquica): {acc_combined:.4f}\")\n",
    "    print(f\"   Impacto da propagação: {impacto_propagacao:+.4f}\")\n",
    "    \n",
    "    # Matriz de confusão por etapa\n",
    "    print(f\"\\n📈 MATRIZES DE CONFUSÃO:\")\n",
    "    \n",
    "    # Espécie\n",
    "    print(f\"\\n🌱 CLASSIFICAÇÃO DE ESPÉCIE:\")\n",
    "    especies_reais = df_resultados['especie_real'].values\n",
    "    especies_pred = df_resultados['especie_predita'].values\n",
    "    print(classification_report(especies_reais, especies_pred, zero_division=0))\n",
    "    \n",
    "    # Saúde\n",
    "    print(f\"\\n🏥 CLASSIFICAÇÃO DE SAÚDE:\")\n",
    "    saude_reais = df_resultados['saude_real'].values\n",
    "    saude_pred = df_resultados['saude_predita'].values\n",
    "    print(classification_report(saude_reais, saude_pred, zero_division=0))\n",
    "    \n",
    "    # Análise por espécie\n",
    "    print(f\"\\n🔬 ANÁLISE POR ESPÉCIE:\")\n",
    "    for especie in df_resultados['especie_real'].unique():\n",
    "        subset = df_resultados[df_resultados['especie_real'] == especie]\n",
    "        acc_esp = subset['acerto_especie'].mean()\n",
    "        acc_sau = subset['acerto_saude'].mean()\n",
    "        acc_comb = subset['acerto_combined'].mean()\n",
    "        \n",
    "        print(f\"   {especie}:\")\n",
    "        print(f\"     Espécie: {acc_esp:.3f} | Saúde: {acc_sau:.3f} | Completo: {acc_comb:.3f}\")\n",
    "    \n",
    "    # Confiança média\n",
    "    print(f\"\\n🎯 ANÁLISE DE CONFIANÇA:\")\n",
    "    conf_especie_media = df_resultados['confianca_especie'].mean()\n",
    "    conf_saude_media = df_resultados['confianca_saude'].mean()\n",
    "    conf_final_media = df_resultados['confianca_final'].mean()\n",
    "    \n",
    "    print(f\"   Confiança média - Espécie: {conf_especie_media:.3f}\")\n",
    "    print(f\"   Confiança média - Saúde: {conf_saude_media:.3f}\")\n",
    "    print(f\"   Confiança média - Final: {conf_final_media:.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'acc_especie': acc_especie,\n",
    "        'acc_saude': acc_saude,\n",
    "        'acc_combined': acc_combined,\n",
    "        'acc_teorica': acc_teorica,\n",
    "        'impacto_propagacao': impacto_propagacao,\n",
    "        'conf_especie_media': conf_especie_media,\n",
    "        'conf_saude_media': conf_saude_media,\n",
    "        'conf_final_media': conf_final_media\n",
    "    }\n",
    "\n",
    "# Executar análise\n",
    "metricas = analisar_propagacao_erros(df_resultados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Calculando baselines para comparação...\n",
      "📊 BASELINE DIRETO (Classificação baseada apenas em espécie):\n",
      "   Método: Predição de espécie + classificação majoritária de saúde\n",
      "   Tomato: classe majoritária = unhealthy\n",
      "   Potato: classe majoritária = unhealthy\n",
      "   Pepper_bell: classe majoritária = healthy\n",
      "   Acertos baseline: 316/450\n",
      "   Acurácia baseline: 0.7022 (70.2%)\n",
      "\n",
      "📊 BASELINE TEÓRICO (Multiplicação de acurácias independentes):\n",
      "   Acurácia espécie: 0.8867 (88.7%)\n",
      "   Acurácia saúde: 0.8667 (86.7%)\n",
      "   Acurácia teórica: 0.7684 (76.8%)\n",
      "\n",
      "📊 RESULTADOS FINAIS:\n",
      "   🔗 Pipeline Hierárquico: 0.7689 (76.9%)\n",
      "   📍 Baseline Direto: 0.7022 (70.2%)\n",
      "   📐 Baseline Teórico: 0.7684 (76.8%)\n",
      "\n",
      "📈 COMPARAÇÕES:\n",
      "   vs Baseline Direto: +0.0667 (+6.7%)\n",
      "   vs Baseline Teórico: +0.0004 (+0.0%)\n",
      "\n",
      "🔬 ANÁLISE DETALHADA:\n",
      "   • Acurácia por etapa:\n",
      "     - Espécie: 0.8867 (88.7%)\n",
      "     - Saúde: 0.8667 (86.7%)\n",
      "     - Completo: 0.7689 (76.9%)\n",
      "   • Confiança média:\n",
      "     - Espécie: 0.867\n",
      "     - Saúde: 0.845\n",
      "     - Final: 0.731\n",
      "\n",
      "🎯 CONCLUSÕES:\n",
      "   ✅ Pipeline hierárquico superou o baseline direto em 6.7%\n",
      "   ⚖️ Pipeline hierárquico está muito próximo do baseline teórico (diferença: 0.0%)\n"
     ]
    }
   ],
   "source": [
    "# 6. IMPLEMENTAÇÃO DE BASELINE PARA COMPARAÇÃO\n",
    "def calcular_baseline_direto(df_resultados):\n",
    "    \"\"\"\n",
    "    Calcula acurácia baseline mais realista simulando um classificador direto\n",
    "    que usa apenas as predições de espécie (sem hierarquia)\n",
    "    \"\"\"\n",
    "    \n",
    "    # BASELINE REALISTA: Usar apenas as predições de espécie + assumir saúde majoritária\n",
    "    # Isso simula um classificador que só identifica espécie e \"chuta\" a saúde\n",
    "    \n",
    "    print(\"📊 BASELINE DIRETO (Classificação baseada apenas em espécie):\")\n",
    "    print(\"   Método: Predição de espécie + classificação majoritária de saúde\")\n",
    "    \n",
    "    # Calcular a classe majoritária de saúde por espécie no conjunto de dados\n",
    "    classes_majoritarias = {}\n",
    "    for especie in df_resultados['especie_real'].unique():\n",
    "        subset = df_resultados[df_resultados['especie_real'] == especie]\n",
    "        classe_majoritaria = subset['saude_real'].mode()[0]  # Classe mais comum\n",
    "        classes_majoritarias[especie] = classe_majoritaria\n",
    "        \n",
    "        print(f\"   {especie}: classe majoritária = {classe_majoritaria}\")\n",
    "    \n",
    "    # Simular baseline: usar predição de espécie + classe majoritária de saúde\n",
    "    acertos_baseline = 0\n",
    "    total_amostras = len(df_resultados)\n",
    "    \n",
    "    for idx, row in df_resultados.iterrows():\n",
    "        # Usar a predição de espécie do pipeline hierárquico\n",
    "        especie_pred = row['especie_predita']\n",
    "        \n",
    "        # Usar classe majoritária de saúde para essa espécie\n",
    "        saude_baseline = classes_majoritarias.get(especie_pred, 'unhealthy')\n",
    "        \n",
    "        # Construir resultado baseline\n",
    "        resultado_baseline = f\"{especie_pred}_{saude_baseline}\"\n",
    "        \n",
    "        # Verificar se acertou\n",
    "        if resultado_baseline == row['combined_real']:\n",
    "            acertos_baseline += 1\n",
    "    \n",
    "    acc_baseline = acertos_baseline / total_amostras\n",
    "    \n",
    "    print(f\"   Acertos baseline: {acertos_baseline}/{total_amostras}\")\n",
    "    print(f\"   Acurácia baseline: {acc_baseline:.4f} ({acc_baseline*100:.1f}%)\")\n",
    "    \n",
    "    return acc_baseline\n",
    "\n",
    "def calcular_baseline_teorico(df_resultados):\n",
    "    \"\"\"\n",
    "    Calcula o baseline teórico baseado na multiplicação das acurácias independentes\n",
    "    \"\"\"\n",
    "    \n",
    "    acc_especie = df_resultados['acerto_especie'].mean()\n",
    "    acc_saude = df_resultados['acerto_saude'].mean()\n",
    "    acc_teorico = acc_especie * acc_saude\n",
    "    \n",
    "    print(f\"\\n📊 BASELINE TEÓRICO (Multiplicação de acurácias independentes):\")\n",
    "    print(f\"   Acurácia espécie: {acc_especie:.4f} ({acc_especie*100:.1f}%)\")\n",
    "    print(f\"   Acurácia saúde: {acc_saude:.4f} ({acc_saude*100:.1f}%)\")\n",
    "    print(f\"   Acurácia teórica: {acc_teorico:.4f} ({acc_teorico*100:.1f}%)\")\n",
    "    \n",
    "    return acc_teorico\n",
    "\n",
    "# Calcular baselines\n",
    "print(\"🔍 Calculando baselines para comparação...\")\n",
    "acc_baseline_direto = calcular_baseline_direto(df_resultados)\n",
    "acc_baseline_teorico = calcular_baseline_teorico(df_resultados)\n",
    "\n",
    "# 7. COMPARAÇÃO FINAL E CONCLUSÕES\n",
    "def comparacao_final(metricas, acc_baseline_direto, acc_baseline_teorico):\n",
    "    \"\"\"\n",
    "    Compara pipeline hierárquico com diferentes baselines\n",
    "    \"\"\"\n",
    "    \n",
    "    acc_hierarquico = metricas['acc_combined']\n",
    "    diferenca_direto = acc_hierarquico - acc_baseline_direto\n",
    "    diferenca_teorico = acc_hierarquico - acc_baseline_teorico\n",
    "    \n",
    "    print(\"\\n📊 RESULTADOS FINAIS:\")\n",
    "    print(f\"   🔗 Pipeline Hierárquico: {acc_hierarquico:.4f} ({acc_hierarquico*100:.1f}%)\")\n",
    "    print(f\"   📍 Baseline Direto: {acc_baseline_direto:.4f} ({acc_baseline_direto*100:.1f}%)\")\n",
    "    print(f\"   📐 Baseline Teórico: {acc_baseline_teorico:.4f} ({acc_baseline_teorico*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n📈 COMPARAÇÕES:\")\n",
    "    print(f\"   vs Baseline Direto: {diferenca_direto:+.4f} ({diferenca_direto*100:+.1f}%)\")\n",
    "    print(f\"   vs Baseline Teórico: {diferenca_teorico:+.4f} ({diferenca_teorico*100:+.1f}%)\")\n",
    "    \n",
    "    # Análise adicional\n",
    "    print(f\"\\n🔬 ANÁLISE DETALHADA:\")\n",
    "    print(f\"   • Acurácia por etapa:\")\n",
    "    print(f\"     - Espécie: {metricas['acc_especie']:.4f} ({metricas['acc_especie']*100:.1f}%)\")\n",
    "    print(f\"     - Saúde: {metricas['acc_saude']:.4f} ({metricas['acc_saude']*100:.1f}%)\")\n",
    "    print(f\"     - Completo: {metricas['acc_combined']:.4f} ({metricas['acc_combined']*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"   • Confiança média:\")\n",
    "    print(f\"     - Espécie: {metricas['conf_especie_media']:.3f}\")\n",
    "    print(f\"     - Saúde: {metricas['conf_saude_media']:.3f}\")\n",
    "    print(f\"     - Final: {metricas['conf_final_media']:.3f}\")\n",
    "    \n",
    "    print(f\"\\n🎯 CONCLUSÕES:\")\n",
    "    if diferenca_direto > 0:\n",
    "        print(f\"   ✅ Pipeline hierárquico superou o baseline direto em {abs(diferenca_direto)*100:.1f}%\")\n",
    "    else:\n",
    "        print(f\"   ❌ Pipeline hierárquico ficou {abs(diferenca_direto)*100:.1f}% abaixo do baseline direto\")\n",
    "    \n",
    "    if abs(diferenca_teorico) < 0.01:\n",
    "        print(f\"   ⚖️ Pipeline hierárquico está muito próximo do baseline teórico (diferença: {diferenca_teorico*100:.1f}%)\")\n",
    "    elif diferenca_teorico > 0:\n",
    "        print(f\"   ✅ Pipeline hierárquico superou o baseline teórico em {abs(diferenca_teorico)*100:.1f}%\")\n",
    "    else:\n",
    "        print(f\"   ❌ Pipeline hierárquico ficou {abs(diferenca_teorico)*100:.1f}% abaixo do baseline teórico\")\n",
    "    \n",
    "    return {\n",
    "        'acc_hierarquico': acc_hierarquico,\n",
    "        'acc_baseline_direto': acc_baseline_direto,\n",
    "        'acc_baseline_teorico': acc_baseline_teorico,\n",
    "        'diferenca_direto': diferenca_direto,\n",
    "        'diferenca_teorico': diferenca_teorico,\n",
    "    }\n",
    "\n",
    "# Executar comparação final\n",
    "comparacao = comparacao_final(metricas, acc_baseline_direto, acc_baseline_teorico)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 INTERPRETAÇÃO DOS BASELINES:\n",
      "============================================================\n",
      "\n",
      "1️⃣ BASELINE DIRETO (Espécie + Classe Majoritária):\n",
      "   • Usa a mesma predição de espécie do pipeline hierárquico\n",
      "   • Para saúde, sempre escolhe a classe majoritária (mais comum)\n",
      "   • Representa um classificador simples que 'chuta' a saúde\n",
      "   • Mais realista para comparação com pipeline hierárquico\n",
      "\n",
      "2️⃣ BASELINE TEÓRICO (Multiplicação de Acurácias):\n",
      "   • Multiplica: Acurácia_Espécie × Acurácia_Saúde\n",
      "   • Assume que os erros são independentes\n",
      "   • Representa o limite teórico se não houvesse correlação\n",
      "   • Útil para detectar se hierarquia ajuda ou atrapalha\n",
      "\n",
      "🔍 ANÁLISE DA DISTRIBUIÇÃO DE CLASSES:\n",
      "   Distribuição de saúde por espécie (dados reais):\n",
      "   • Tomato: 30 healthy, 270 unhealthy\n",
      "     Proporção unhealthy: 90.0%\n",
      "   • Potato: 30 healthy, 60 unhealthy\n",
      "     Proporção unhealthy: 66.7%\n",
      "   • Pepper_bell: 30 healthy, 30 unhealthy\n",
      "     Proporção unhealthy: 50.0%\n",
      "\n",
      "💡 INTERPRETAÇÃO DOS RESULTADOS:\n",
      "   • Se Pipeline ≈ Baseline Teórico → Hierarquia não interfere\n",
      "   • Se Pipeline > Baseline Teórico → Hierarquia está ajudando\n",
      "   • Se Pipeline < Baseline Teórico → Hierarquia está atrapalhando\n",
      "   • Se Pipeline > Baseline Direto → Classificação de saúde é útil\n",
      "\n",
      "🔬 ANÁLISE DE ERROS POR COMBINAÇÃO:\n",
      "   Total de erros: 104\n",
      "\n",
      "   Tipos de erro:\n",
      "   • Erro apenas na espécie: 51\n",
      "   • Erro apenas na saúde: 53\n",
      "   • Erro em ambos: 7\n",
      "\n",
      "🎯 EFICIÊNCIA DO PIPELINE:\n",
      "   • Eficiência vs Teórico: 100.1%\n",
      "   • Eficiência vs Direto: 109.5%\n",
      "   ✅ Pipeline hierárquico está funcionando muito bem!\n"
     ]
    }
   ],
   "source": [
    "# 8. ANÁLISE ADICIONAL E INTERPRETAÇÃO DOS RESULTADOS\n",
    "\n",
    "print(\"📚 INTERPRETAÇÃO DOS BASELINES:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1️⃣ BASELINE DIRETO (Espécie + Classe Majoritária):\")\n",
    "print(\"   • Usa a mesma predição de espécie do pipeline hierárquico\")\n",
    "print(\"   • Para saúde, sempre escolhe a classe majoritária (mais comum)\")\n",
    "print(\"   • Representa um classificador simples que 'chuta' a saúde\")\n",
    "print(\"   • Mais realista para comparação com pipeline hierárquico\")\n",
    "\n",
    "print(\"\\n2️⃣ BASELINE TEÓRICO (Multiplicação de Acurácias):\")\n",
    "print(\"   • Multiplica: Acurácia_Espécie × Acurácia_Saúde\")\n",
    "print(\"   • Assume que os erros são independentes\")\n",
    "print(\"   • Representa o limite teórico se não houvesse correlação\")\n",
    "print(\"   • Útil para detectar se hierarquia ajuda ou atrapalha\")\n",
    "\n",
    "print(\"\\n🔍 ANÁLISE DA DISTRIBUIÇÃO DE CLASSES:\")\n",
    "print(\"   Distribuição de saúde por espécie (dados reais):\")\n",
    "\n",
    "for especie in df_resultados['especie_real'].unique():\n",
    "    subset = df_resultados[df_resultados['especie_real'] == especie]\n",
    "    healthy_count = len(subset[subset['saude_real'] == 'healthy'])\n",
    "    unhealthy_count = len(subset[subset['saude_real'] == 'unhealthy'])\n",
    "    total = len(subset)\n",
    "    \n",
    "    print(f\"   • {especie}: {healthy_count} healthy, {unhealthy_count} unhealthy\")\n",
    "    print(f\"     Proporção unhealthy: {unhealthy_count/total:.1%}\")\n",
    "\n",
    "print(\"\\n💡 INTERPRETAÇÃO DOS RESULTADOS:\")\n",
    "print(\"   • Se Pipeline ≈ Baseline Teórico → Hierarquia não interfere\")\n",
    "print(\"   • Se Pipeline > Baseline Teórico → Hierarquia está ajudando\")\n",
    "print(\"   • Se Pipeline < Baseline Teórico → Hierarquia está atrapalhando\")\n",
    "print(\"   • Se Pipeline > Baseline Direto → Classificação de saúde é útil\")\n",
    "\n",
    "# Análise de erros por combinação\n",
    "print(f\"\\n🔬 ANÁLISE DE ERROS POR COMBINAÇÃO:\")\n",
    "erros_combinacao = df_resultados[df_resultados['acerto_combined'] == False]\n",
    "print(f\"   Total de erros: {len(erros_combinacao)}\")\n",
    "\n",
    "print(\"\\n   Tipos de erro:\")\n",
    "erro_apenas_especie = len(erros_combinacao[erros_combinacao['acerto_especie'] == False])\n",
    "erro_apenas_saude = len(erros_combinacao[\n",
    "    (erros_combinacao['acerto_especie'] == True) & \n",
    "    (erros_combinacao['acerto_saude'] == False)\n",
    "])\n",
    "erro_ambos = len(erros_combinacao[\n",
    "    (erros_combinacao['acerto_especie'] == False) & \n",
    "    (erros_combinacao['acerto_saude'] == False)\n",
    "])\n",
    "\n",
    "print(f\"   • Erro apenas na espécie: {erro_apenas_especie}\")\n",
    "print(f\"   • Erro apenas na saúde: {erro_apenas_saude}\")\n",
    "print(f\"   • Erro em ambos: {erro_ambos}\")\n",
    "\n",
    "print(f\"\\n🎯 EFICIÊNCIA DO PIPELINE:\")\n",
    "acc_hierarquico = comparacao['acc_hierarquico']\n",
    "acc_teorico = comparacao['acc_baseline_teorico']\n",
    "acc_direto = comparacao['acc_baseline_direto']\n",
    "\n",
    "eficiencia_teorica = (acc_hierarquico / acc_teorico) * 100\n",
    "eficiencia_direta = (acc_hierarquico / acc_direto) * 100\n",
    "\n",
    "print(f\"   • Eficiência vs Teórico: {eficiencia_teorica:.1f}%\")\n",
    "print(f\"   • Eficiência vs Direto: {eficiencia_direta:.1f}%\")\n",
    "\n",
    "if eficiencia_teorica > 95:\n",
    "    print(\"   ✅ Pipeline hierárquico está funcionando muito bem!\")\n",
    "elif eficiencia_teorica > 85:\n",
    "    print(\"   ✅ Pipeline hierárquico está funcionando bem\")\n",
    "else:\n",
    "    print(\"   ⚠️ Pipeline hierárquico pode ser melhorado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 RELATÓRIO FINAL SALVO:\n",
      "   • Arquivo: datasets_processados/relatorio_pipeline_hierarquico.json\n",
      "   • Resultados detalhados: datasets_processados/resultados_pipeline_hierarquico.csv\n",
      "   • Conjunto de teste: datasets_processados/conjunto_teste_hierarquico.csv\n",
      "\n",
      "🎯 RESUMO EXECUTIVO:\n",
      "   • Pipeline Hierárquico: 76.9%\n",
      "   • Baseline Direto: 70.2%\n",
      "   • Baseline Teórico: 76.8%\n",
      "   • Eficiência: 100.1%\n",
      "\n",
      "✅ ANÁLISE COMPLETA DO PIPELINE HIERÁRQUICO CONCLUÍDA!\n",
      "   Todos os resultados foram salvos para análise posterior.\n"
     ]
    }
   ],
   "source": [
    "# 9. SALVAMENTO DO RELATÓRIO FINAL\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Preparar dados para salvamento\n",
    "relatorio_final = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'metricas_pipeline': {\n",
    "        'acuracia_especie': float(metricas['acc_especie']),\n",
    "        'acuracia_saude': float(metricas['acc_saude']),\n",
    "        'acuracia_completa': float(metricas['acc_combined']),\n",
    "        'confianca_especie': float(metricas['conf_especie_media']),\n",
    "        'confianca_saude': float(metricas['conf_saude_media']),\n",
    "        'confianca_final': float(metricas['conf_final_media'])\n",
    "    },\n",
    "    'baselines': {\n",
    "        'direto': float(comparacao['acc_baseline_direto']),\n",
    "        'teorico': float(comparacao['acc_baseline_teorico'])\n",
    "    },\n",
    "    'comparacoes': {\n",
    "        'diferenca_vs_direto': float(comparacao['diferenca_direto']),\n",
    "        'diferenca_vs_teorico': float(comparacao['diferenca_teorico']),\n",
    "        'eficiencia_teorica': float(eficiencia_teorica),\n",
    "        'eficiencia_direta': float(eficiencia_direta)\n",
    "    },\n",
    "    'analise_erros': {\n",
    "        'total_erros': int(len(erros_combinacao)),\n",
    "        'erro_apenas_especie': int(erro_apenas_especie),\n",
    "        'erro_apenas_saude': int(erro_apenas_saude),\n",
    "        'erro_ambos': int(erro_ambos)\n",
    "    },\n",
    "    'total_amostras': int(len(df_resultados))\n",
    "}\n",
    "\n",
    "# Salvar relatório\n",
    "with open('datasets_processados/relatorio_pipeline_hierarquico.json', 'w') as f:\n",
    "    json.dump(relatorio_final, f, indent=2)\n",
    "\n",
    "print(\"📝 RELATÓRIO FINAL SALVO:\")\n",
    "print(\"   • Arquivo: datasets_processados/relatorio_pipeline_hierarquico.json\")\n",
    "print(\"   • Resultados detalhados: datasets_processados/resultados_pipeline_hierarquico.csv\")\n",
    "print(\"   • Conjunto de teste: datasets_processados/conjunto_teste_hierarquico.csv\")\n",
    "\n",
    "print(f\"\\n🎯 RESUMO EXECUTIVO:\")\n",
    "print(f\"   • Pipeline Hierárquico: {metricas['acc_combined']:.1%}\")\n",
    "print(f\"   • Baseline Direto: {comparacao['acc_baseline_direto']:.1%}\")\n",
    "print(f\"   • Baseline Teórico: {comparacao['acc_baseline_teorico']:.1%}\")\n",
    "print(f\"   • Eficiência: {eficiencia_teorica:.1f}%\")\n",
    "\n",
    "print(f\"\\n✅ ANÁLISE COMPLETA DO PIPELINE HIERÁRQUICO CONCLUÍDA!\")\n",
    "print(\"   Todos os resultados foram salvos para análise posterior.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
