{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelos Especialistas\n",
        "\n",
        "**Objetivo**: Criar modelos especialistas que classificam em:\n",
        "- **HEALTHY**: Planta saudÃ¡vel\n",
        "- **UNHEALTHY**: Planta doente (qualquer doenÃ§a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== CARREGANDO DATASETS BINÃRIOS CORRIGIDOS ===\n",
            "ðŸ“‚ Carregando dataset de tomato...\n",
            "   ðŸ¦  Tomato_Bacterial_spot: 2127 â†’ UNHEALTHY\n",
            "   ðŸ¦  Tomato_Early_blight: 1000 â†’ UNHEALTHY\n",
            "   ðŸ¦  Tomato_Late_blight: 1909 â†’ UNHEALTHY\n",
            "   ðŸ¦  Tomato_Leaf_Mold: 952 â†’ UNHEALTHY\n",
            "   ðŸ¦  Tomato_Septoria_leaf_spot: 1771 â†’ UNHEALTHY\n",
            "   ðŸ¦  Tomato_Spider_mites_Two_spotted_spider_mite: 1676 â†’ UNHEALTHY\n",
            "   ðŸ¦  Tomato__Target_Spot: 1404 â†’ UNHEALTHY\n",
            "   ðŸ¦  Tomato__Tomato_YellowLeaf__Curl_Virus: 3208 â†’ UNHEALTHY\n",
            "   ðŸ¦  Tomato__Tomato_mosaic_virus: 373 â†’ UNHEALTHY\n",
            "   âœ… Tomato_healthy: 1591 â†’ HEALTHY\n",
            "   ðŸ“Š Total: 16011 | Healthy: 1591 (9.9%) | Unhealthy: 14420 (90.1%)\n",
            "\n",
            "ðŸ“‚ Carregando dataset de potato...\n",
            "   ðŸ¦  Potato___Early_blight: 1000 â†’ UNHEALTHY\n",
            "   ðŸ¦  Potato___Late_blight: 1000 â†’ UNHEALTHY\n",
            "   âœ… Potato___healthy: 152 â†’ HEALTHY\n",
            "   ðŸ“Š Total: 2152 | Healthy: 152 (7.1%) | Unhealthy: 2000 (92.9%)\n",
            "\n",
            "ðŸ“‚ Carregando dataset de pepper_bell...\n",
            "   ðŸ¦  Pepper__bell___Bacterial_spot: 997 â†’ UNHEALTHY\n",
            "   âœ… Pepper__bell___healthy: 1478 â†’ HEALTHY\n",
            "   ðŸ“Š Total: 2475 | Healthy: 1478 (59.7%) | Unhealthy: 997 (40.3%)\n",
            "\n",
            "âœ… DATASETS BINÃRIOS CARREGADOS: Tomato, Potato, Pepper\n"
          ]
        }
      ],
      "source": [
        "# 1. CARREGAMENTO DE DADOS\n",
        "from utils import *\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import pandas as pd\n",
        "\n",
        "config = carregar_configuracoes()\n",
        "\n",
        "def carregar_dataset(especie):\n",
        "    \"\"\"Carrega dataset agrupando todas as doenÃ§as\"\"\"\n",
        "    print(f\"ðŸ“‚ Carregando dataset de {especie}...\")\n",
        "    \n",
        "    # Construir dataset_info\n",
        "    dataset_info = {}\n",
        "    for esp, info in config['especialistas'].items():\n",
        "        for classe in info['classes']:\n",
        "            dataset_info[classe] = {}\n",
        "    \n",
        "    healthy_images = []\n",
        "    unhealthy_images = []\n",
        "    \n",
        "    # Processar cada classe da espÃ©cie\n",
        "    for classe, info in dataset_info.items():\n",
        "        # Remover underscores \n",
        "        classe_normalizada = classe.lower().replace('_', '')\n",
        "        especie_normalizada = especie.lower().replace('_', '')\n",
        "        \n",
        "        if especie_normalizada in classe_normalizada:\n",
        "            # Usar base_path como diretÃ³rio base das imagens\n",
        "            dir_path = os.path.join(config.get('processed_data_path', config['base_path']), classe)\n",
        "            \n",
        "            if not os.path.exists(dir_path):\n",
        "                print(f\"   âš ï¸ DiretÃ³rio nÃ£o encontrado: {dir_path}\")\n",
        "                continue\n",
        "                \n",
        "            images_in_dir = []\n",
        "            for img_name in os.listdir(dir_path):\n",
        "                if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    images_in_dir.append(os.path.join(dir_path, img_name))\n",
        "            \n",
        "            # AGRUPAMENTO BINÃRIO\n",
        "            if 'healthy' in classe.lower():\n",
        "                healthy_images.extend(images_in_dir)\n",
        "                print(f\"   âœ… {classe}: {len(images_in_dir)} â†’ HEALTHY\")\n",
        "            else:\n",
        "                unhealthy_images.extend(images_in_dir)\n",
        "                print(f\"   ðŸ¦  {classe}: {len(images_in_dir)} â†’ UNHEALTHY\")\n",
        "    \n",
        "    # Combinar dados\n",
        "    all_images = healthy_images + unhealthy_images\n",
        "    all_labels = ['healthy'] * len(healthy_images) + ['unhealthy'] * len(unhealthy_images)\n",
        "    \n",
        "    # ProteÃ§Ã£o contra divisÃ£o por zero\n",
        "    if len(all_images) == 0:\n",
        "        print(f\"   âŒ ERRO: Nenhuma imagem encontrada para {especie}!\")\n",
        "        print(f\"   ðŸ” Verifique se as pastas existem e contÃªm imagens.\")\n",
        "        return None\n",
        "    \n",
        "    balance_ratio = len(healthy_images) / len(all_images) * 100\n",
        "    print(f\"   ðŸ“Š Total: {len(all_images)} | Healthy: {len(healthy_images)} ({balance_ratio:.1f}%) | Unhealthy: {len(unhealthy_images)} ({100-balance_ratio:.1f}%)\")\n",
        "    \n",
        "    # Dividindo em treino, validaÃ§Ã£o e teste para todos os datasets\n",
        "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "        all_images, all_labels, test_size=0.15, stratify=all_labels, random_state=42\n",
        "    )\n",
        "    \n",
        "    # Dividindo em treino, validaÃ§Ã£o e teste para cada dataset\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_temp, y_temp, test_size=0.176, stratify=y_temp, random_state=42\n",
        "    )\n",
        "    \n",
        "    return {\n",
        "        'train': {'X': X_train, 'y': y_train},\n",
        "        'val': {'X': X_val, 'y': y_val},\n",
        "        'test': {'X': X_test, 'y': y_test},\n",
        "        'info': {'balance_ratio': balance_ratio, 'total': len(all_images)}\n",
        "    }\n",
        "\n",
        "# Carregar datasets binÃ¡rios reais\n",
        "print(\"=== CARREGANDO DATASETS BINÃRIOS CORRIGIDOS ===\")\n",
        "dataset_tomato = carregar_dataset('tomato')\n",
        "print()\n",
        "dataset_potato = carregar_dataset('potato')\n",
        "print()\n",
        "dataset_pepper = carregar_dataset('pepper_bell')\n",
        "\n",
        "# Verificar se todos os datasets foram carregados com sucesso\n",
        "datasets_validos = []\n",
        "if dataset_tomato is not None:\n",
        "    datasets_validos.append('Tomato')\n",
        "if dataset_potato is not None:\n",
        "    datasets_validos.append('Potato')    \n",
        "if dataset_pepper is not None:\n",
        "    datasets_validos.append('Pepper')\n",
        "\n",
        "if len(datasets_validos) > 0:\n",
        "    print(f\"\\nâœ… DATASETS BINÃRIOS CARREGADOS: {', '.join(datasets_validos)}\")\n",
        "else:\n",
        "    print(\"\\nâŒ ERRO: Nenhum dataset foi carregado com sucesso!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== CRIANDO GERADORES BINÃRIOS OTIMIZADOS ===\n",
            "Found 11213 validated image filenames belonging to 2 classes.\n",
            "Found 2396 validated image filenames belonging to 2 classes.\n",
            "Found 2402 validated image filenames belonging to 2 classes.\n",
            "Found 1507 validated image filenames belonging to 2 classes.\n",
            "Found 322 validated image filenames belonging to 2 classes.\n",
            "Found 323 validated image filenames belonging to 2 classes.\n",
            "Found 1732 validated image filenames belonging to 2 classes.\n",
            "Found 371 validated image filenames belonging to 2 classes.\n",
            "Found 372 validated image filenames belonging to 2 classes.\n",
            "âœ… Geradores criados com class_mode='binary'\n",
            "\n",
            "=== CRIANDO MODELOS BINÃRIOS OTIMIZADOS ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-03 19:31:07.976698: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-07-03 19:31:08.428191: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-07-03 19:31:08.428228: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-07-03 19:31:08.428232: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
            "2025-07-03 19:31:08.432497: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-07-03 19:31:08.432533: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-07-03 19:31:08.432550: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-07-03 19:31:08.432553: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
            "2025-07-03 19:31:08.525398: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-07-03 19:31:08.525442: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-07-03 19:31:08.525447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
            "2025-07-03 19:31:08.525470: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-07-03 19:31:08.525484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13123 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 5070 Ti, pci bus id: 0000:01:00.0, compute capability: 12.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Modelo binÃ¡rio Tomato: 24,136,961 parÃ¢metros\n",
            "âœ… Modelo binÃ¡rio Potato: 24,136,961 parÃ¢metros\n",
            "âœ… Modelo binÃ¡rio Pepper: 24,136,961 parÃ¢metros\n",
            "\n",
            "=== CALCULANDO CLASS WEIGHTS ===\n",
            "   Class weights: Healthy=5.033, Unhealthy=0.555\n",
            "   Class weights: Healthy=7.108, Unhealthy=0.538\n",
            "   Class weights: Healthy=0.838, Unhealthy=1.241\n"
          ]
        }
      ],
      "source": [
        "# 2. ARQUITETURA E TREINAMENTO OTIMIZADO\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def criar_classificao_binaria(dataset, config):\n",
        "    \"\"\"Cria geradores otimizados para classificaÃ§Ã£o binÃ¡ria\"\"\"\n",
        "    \n",
        "    # Data augmentation para generalizaÃ§Ã£o\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=30,\n",
        "        width_shift_range=0.3,\n",
        "        height_shift_range=0.3,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        zoom_range=0.3,\n",
        "        brightness_range=[0.7, 1.3],\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "    \n",
        "    val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    \n",
        "    # DataFrames\n",
        "    train_df = pd.DataFrame({'filename': dataset['train']['X'], 'class': dataset['train']['y']})\n",
        "    val_df = pd.DataFrame({'filename': dataset['val']['X'], 'class': dataset['val']['y']})\n",
        "    test_df = pd.DataFrame({'filename': dataset['test']['X'], 'class': dataset['test']['y']})\n",
        "    \n",
        "    # Geradores binÃ¡rios\n",
        "    train_gen = train_datagen.flow_from_dataframe(\n",
        "        train_df, x_col='filename', y_col='class',\n",
        "        target_size=(config['img_height'], config['img_width']),\n",
        "        batch_size=config['batch_size'],\n",
        "        class_mode='binary', shuffle=True, seed=42\n",
        "    )\n",
        "    \n",
        "    val_gen = val_test_datagen.flow_from_dataframe(\n",
        "        val_df, x_col='filename', y_col='class',\n",
        "        target_size=(config['img_height'], config['img_width']),\n",
        "        batch_size=config['batch_size'],\n",
        "        class_mode='binary', shuffle=False, seed=42\n",
        "    )\n",
        "    \n",
        "    test_gen = val_test_datagen.flow_from_dataframe(\n",
        "        test_df, x_col='filename', y_col='class',\n",
        "        target_size=(config['img_height'], config['img_width']),\n",
        "        batch_size=config['batch_size'],\n",
        "        class_mode='binary', shuffle=False, seed=42\n",
        "    )\n",
        "    \n",
        "    return train_gen, val_gen, test_gen\n",
        "\n",
        "def criar_modelo(especie_nome):\n",
        "    \"\"\"Cria modelo de classificaÃ§Ã£o binÃ¡ria\"\"\"\n",
        "    base_model = ResNet50(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(224, 224, 3)\n",
        "    )\n",
        "    \n",
        "    # Descongelar Ãºltimas camadas\n",
        "    base_model.trainable = True\n",
        "    for layer in base_model.layers[:-15]:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    # Arquitetura otimizada para classificaÃ§Ã£o binÃ¡ria\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "    x = Dropout(0.6)(x)\n",
        "    x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    \n",
        "    # SaÃ­da binÃ¡ria com sigmoid\n",
        "    predictions = Dense(1, activation='sigmoid', name=f'output_{especie_nome}')(x)\n",
        "    \n",
        "    modelo = Model(inputs=base_model.input, outputs=predictions)\n",
        "    \n",
        "    print(f\"âœ… Modelo binÃ¡rio {especie_nome}: {modelo.count_params():,} parÃ¢metros\")\n",
        "    return modelo\n",
        "\n",
        "def calcular_class_weights(dataset):\n",
        "    \"\"\"Calcula class weights balanceados\"\"\"\n",
        "    healthy_count = sum(1 for label in dataset['train']['y'] if label == 'healthy')\n",
        "    unhealthy_count = len(dataset['train']['y']) - healthy_count\n",
        "    \n",
        "    total = len(dataset['train']['y'])\n",
        "    weight_healthy = total / (2 * healthy_count)\n",
        "    weight_unhealthy = total / (2 * unhealthy_count)\n",
        "    \n",
        "    class_weights = {0: weight_healthy, 1: weight_unhealthy}  # 0=healthy, 1=unhealthy\n",
        "    \n",
        "    print(f\"   Class weights: Healthy={weight_healthy:.3f}, Unhealthy={weight_unhealthy:.3f}\")\n",
        "    return class_weights\n",
        "\n",
        "# Criar geradores\n",
        "print(\"=== CRIANDO GERADORES BINÃRIOS OTIMIZADOS ===\")\n",
        "train_gen_tomato, val_gen_tomato, test_gen_tomato = criar_classificao_binaria(dataset_tomato, config)\n",
        "train_gen_potato, val_gen_potato, test_gen_potato = criar_classificao_binaria(dataset_potato, config)\n",
        "train_gen_pepper, val_gen_pepper, test_gen_pepper = criar_classificao_binaria(dataset_pepper, config)\n",
        "\n",
        "print(f\"âœ… Geradores criados com class_mode='binary'\")\n",
        "\n",
        "# Criar modelos\n",
        "print(\"\\n=== CRIANDO MODELOS BINÃRIOS OTIMIZADOS ===\")\n",
        "modelo_tomato = criar_modelo('Tomato')\n",
        "modelo_potato = criar_modelo('Potato')\n",
        "modelo_pepper = criar_modelo('Pepper')\n",
        "\n",
        "# Calcular class weights\n",
        "print(\"\\n=== CALCULANDO CLASS WEIGHTS ===\")\n",
        "cw_tomato = calcular_class_weights(dataset_tomato)\n",
        "cw_potato = calcular_class_weights(dataset_potato)\n",
        "cw_pepper = calcular_class_weights(dataset_pepper)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== TREINAMENTO DOS MODELOS BINÃRIOS ===\n",
            "\n",
            "ðŸš€ Treinando Tomato...\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-03 19:31:13.520236: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
            "2025-07-03 19:31:15.321000: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f618592e7d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2025-07-03 19:31:15.321028: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 5070 Ti, Compute Capability 12.0\n",
            "2025-07-03 19:31:15.334028: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1751581875.396423  111812 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "351/351 [==============================] - ETA: 0s - loss: 1.1789 - accuracy: 0.7178"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/gustavo/.pyenv/versions/3.10.14/envs/tf-gpu-env/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "351/351 [==============================] - 59s 153ms/step - loss: 1.1789 - accuracy: 0.7178 - val_loss: 0.9310 - val_accuracy: 0.8952 - lr: 1.0000e-04\n",
            "Epoch 2/40\n",
            "351/351 [==============================] - 52s 147ms/step - loss: 0.9431 - accuracy: 0.7983 - val_loss: 0.7889 - val_accuracy: 0.8856 - lr: 1.0000e-04\n",
            "Epoch 3/40\n",
            "351/351 [==============================] - 51s 146ms/step - loss: 0.8991 - accuracy: 0.8189 - val_loss: 0.9101 - val_accuracy: 0.8076 - lr: 1.0000e-04\n",
            "Epoch 4/40\n",
            "351/351 [==============================] - 52s 148ms/step - loss: 0.8804 - accuracy: 0.8331 - val_loss: 1.5843 - val_accuracy: 0.5288 - lr: 1.0000e-04\n",
            "Epoch 5/40\n",
            "351/351 [==============================] - 51s 146ms/step - loss: 0.8397 - accuracy: 0.8377 - val_loss: 1.2613 - val_accuracy: 0.6365 - lr: 1.0000e-04\n",
            "Epoch 6/40\n",
            "351/351 [==============================] - 52s 147ms/step - loss: 0.8169 - accuracy: 0.8427 - val_loss: 0.7427 - val_accuracy: 0.8977 - lr: 1.0000e-04\n",
            "Epoch 7/40\n",
            "351/351 [==============================] - 51s 146ms/step - loss: 0.7972 - accuracy: 0.8463 - val_loss: 0.8220 - val_accuracy: 0.8427 - lr: 1.0000e-04\n",
            "Epoch 8/40\n",
            "351/351 [==============================] - 51s 145ms/step - loss: 0.7829 - accuracy: 0.8494 - val_loss: 1.2930 - val_accuracy: 0.6127 - lr: 1.0000e-04\n",
            "Epoch 9/40\n",
            "351/351 [==============================] - 52s 147ms/step - loss: 0.7260 - accuracy: 0.8679 - val_loss: 2.0559 - val_accuracy: 0.4850 - lr: 1.0000e-04\n",
            "Epoch 10/40\n",
            "351/351 [==============================] - 51s 146ms/step - loss: 0.7054 - accuracy: 0.8660 - val_loss: 0.9194 - val_accuracy: 0.7759 - lr: 1.0000e-04\n",
            "Epoch 11/40\n",
            "351/351 [==============================] - 52s 149ms/step - loss: 0.7031 - accuracy: 0.8686 - val_loss: 0.5814 - val_accuracy: 0.9508 - lr: 1.0000e-04\n",
            "Epoch 12/40\n",
            "351/351 [==============================] - 52s 147ms/step - loss: 0.6623 - accuracy: 0.8782 - val_loss: 0.7550 - val_accuracy: 0.8472 - lr: 1.0000e-04\n",
            "Epoch 13/40\n",
            "351/351 [==============================] - 51s 146ms/step - loss: 0.6393 - accuracy: 0.8760 - val_loss: 0.6024 - val_accuracy: 0.8977 - lr: 1.0000e-04\n",
            "Epoch 14/40\n",
            "351/351 [==============================] - 51s 146ms/step - loss: 0.6406 - accuracy: 0.8700 - val_loss: 0.4870 - val_accuracy: 0.9491 - lr: 1.0000e-04\n",
            "Epoch 15/40\n",
            "351/351 [==============================] - 51s 145ms/step - loss: 0.6146 - accuracy: 0.8761 - val_loss: 0.9867 - val_accuracy: 0.7513 - lr: 1.0000e-04\n",
            "Epoch 16/40\n",
            "351/351 [==============================] - -106s -303801us/step - loss: 0.5901 - accuracy: 0.8764 - val_loss: 1.6231 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 17/40\n",
            "351/351 [==============================] - 51s 146ms/step - loss: 0.5607 - accuracy: 0.8828 - val_loss: 0.8723 - val_accuracy: 0.7642 - lr: 1.0000e-04\n",
            "Epoch 18/40\n",
            "351/351 [==============================] - 51s 147ms/step - loss: 0.5519 - accuracy: 0.8833 - val_loss: 2.0887 - val_accuracy: 0.4161 - lr: 1.0000e-04\n",
            "Epoch 19/40\n",
            "351/351 [==============================] - 209s 596ms/step - loss: 0.5161 - accuracy: 0.8944 - val_loss: 0.4288 - val_accuracy: 0.9491 - lr: 1.0000e-04\n",
            "Epoch 20/40\n",
            "351/351 [==============================] - -106s 146ms/step - loss: 0.5020 - accuracy: 0.8953 - val_loss: 1.3424 - val_accuracy: 0.6398 - lr: 1.0000e-04\n",
            "Epoch 21/40\n",
            "351/351 [==============================] - 51s 145ms/step - loss: 0.4832 - accuracy: 0.8898 - val_loss: 5.3263 - val_accuracy: 0.1740 - lr: 1.0000e-04\n",
            "Epoch 22/40\n",
            "351/351 [==============================] - 51s 145ms/step - loss: 0.4642 - accuracy: 0.8908 - val_loss: 2.0250 - val_accuracy: 0.4687 - lr: 1.0000e-04\n",
            "Epoch 23/40\n",
            "351/351 [==============================] - 209s 598ms/step - loss: 0.4554 - accuracy: 0.8958 - val_loss: 0.3411 - val_accuracy: 0.9491 - lr: 1.0000e-04\n",
            "Epoch 24/40\n",
            "351/351 [==============================] - -106s 146ms/step - loss: 0.4438 - accuracy: 0.9018 - val_loss: 0.5843 - val_accuracy: 0.9457 - lr: 1.0000e-04\n",
            "Epoch 25/40\n",
            "351/351 [==============================] - 51s 146ms/step - loss: 0.4205 - accuracy: 0.8987 - val_loss: 0.3772 - val_accuracy: 0.9270 - lr: 1.0000e-04\n",
            "Epoch 26/40\n",
            "351/351 [==============================] - 51s 146ms/step - loss: 0.4172 - accuracy: 0.8920 - val_loss: 0.5094 - val_accuracy: 0.8656 - lr: 1.0000e-04\n",
            "âœ… Tomato concluÃ­do! Melhor accuracy: 0.9508\n",
            "\n",
            "ðŸš€ Treinando Potato...\n",
            "Epoch 1/40\n",
            "48/48 [==============================] - 10s 157ms/step - loss: 1.4774 - accuracy: 0.7585 - val_loss: 1.0597 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
            "Epoch 2/40\n",
            "48/48 [==============================] - 7s 144ms/step - loss: 1.4016 - accuracy: 0.6921 - val_loss: 1.0982 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
            "Epoch 3/40\n",
            "48/48 [==============================] - 7s 145ms/step - loss: 1.5094 - accuracy: 0.6815 - val_loss: 1.2610 - val_accuracy: 0.4130 - lr: 1.0000e-04\n",
            "Epoch 4/40\n",
            "48/48 [==============================] - 7s 146ms/step - loss: 1.3742 - accuracy: 0.6828 - val_loss: 1.3190 - val_accuracy: 0.2919 - lr: 1.0000e-04\n",
            "Epoch 5/40\n",
            "48/48 [==============================] - 7s 147ms/step - loss: 1.3346 - accuracy: 0.6682 - val_loss: 1.0960 - val_accuracy: 0.7733 - lr: 1.0000e-04\n",
            "Epoch 6/40\n",
            "48/48 [==============================] - 7s 146ms/step - loss: 1.3428 - accuracy: 0.6496 - val_loss: 1.0917 - val_accuracy: 0.7826 - lr: 1.0000e-04\n",
            "Epoch 7/40\n",
            "48/48 [==============================] - 7s 151ms/step - loss: 1.2282 - accuracy: 0.6948 - val_loss: 1.0135 - val_accuracy: 0.8758 - lr: 1.0000e-04\n",
            "Epoch 8/40\n",
            "48/48 [==============================] - 7s 146ms/step - loss: 1.2938 - accuracy: 0.6695 - val_loss: 1.2214 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 9/40\n",
            "48/48 [==============================] - 7s 146ms/step - loss: 1.2620 - accuracy: 0.6530 - val_loss: 1.2631 - val_accuracy: 0.5124 - lr: 1.0000e-04\n",
            "Epoch 10/40\n",
            "48/48 [==============================] - 7s -3210077us/step - loss: 1.1835 - accuracy: 0.6536 - val_loss: 1.4052 - val_accuracy: 0.3851 - lr: 1.0000e-04\n",
            "Epoch 11/40\n",
            "48/48 [==============================] - 7s 144ms/step - loss: 1.2579 - accuracy: 0.6337 - val_loss: 0.8314 - val_accuracy: 0.8789 - lr: 1.0000e-04\n",
            "Epoch 12/40\n",
            "48/48 [==============================] - 7s 145ms/step - loss: 1.1734 - accuracy: 0.6656 - val_loss: 0.8484 - val_accuracy: 0.8789 - lr: 1.0000e-04\n",
            "Epoch 13/40\n",
            "48/48 [==============================] - 7s 145ms/step - loss: 1.3062 - accuracy: 0.6735 - val_loss: 0.9349 - val_accuracy: 0.8075 - lr: 1.0000e-04\n",
            "Epoch 14/40\n",
            "48/48 [==============================] - 7s 145ms/step - loss: 1.2640 - accuracy: 0.6145 - val_loss: 1.0163 - val_accuracy: 0.7360 - lr: 1.0000e-04\n",
            "Epoch 15/40\n",
            "48/48 [==============================] - 7s -3209091us/step - loss: 1.1951 - accuracy: 0.7034 - val_loss: 1.7823 - val_accuracy: 0.3385 - lr: 1.0000e-04\n",
            "Epoch 16/40\n",
            "48/48 [==============================] - 7s 148ms/step - loss: 1.2101 - accuracy: 0.6821 - val_loss: 1.3158 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "âœ… Potato concluÃ­do! Melhor accuracy: 0.9286\n",
            "\n",
            "ðŸš€ Treinando Pepper...\n",
            "Epoch 1/40\n",
            "55/55 [==============================] - 11s 161ms/step - loss: 1.4465 - accuracy: 0.5889 - val_loss: 1.3257 - val_accuracy: 0.4016 - lr: 1.0000e-04\n",
            "Epoch 2/40\n",
            "55/55 [==============================] - 8s 150ms/step - loss: 1.3633 - accuracy: 0.6259 - val_loss: 1.2631 - val_accuracy: 0.4043 - lr: 1.0000e-04\n",
            "Epoch 3/40\n",
            "55/55 [==============================] - 8s 151ms/step - loss: 1.3075 - accuracy: 0.6305 - val_loss: 1.2111 - val_accuracy: 0.6280 - lr: 1.0000e-04\n",
            "Epoch 4/40\n",
            "55/55 [==============================] - 8s 150ms/step - loss: 1.2784 - accuracy: 0.6334 - val_loss: 1.1486 - val_accuracy: 0.7089 - lr: 1.0000e-04\n",
            "Epoch 5/40\n",
            "55/55 [==============================] - 8s 147ms/step - loss: 1.2679 - accuracy: 0.6449 - val_loss: 1.1533 - val_accuracy: 0.6550 - lr: 1.0000e-04\n",
            "Epoch 6/40\n",
            "55/55 [==============================] - 8s 148ms/step - loss: 1.2753 - accuracy: 0.6305 - val_loss: 1.1200 - val_accuracy: 0.6954 - lr: 1.0000e-04\n",
            "Epoch 7/40\n",
            "55/55 [==============================] - 166s 3s/step - loss: 1.2378 - accuracy: 0.6420 - val_loss: 1.1049 - val_accuracy: 0.7385 - lr: 1.0000e-04\n",
            "Epoch 8/40\n",
            "55/55 [==============================] - -150s 147ms/step - loss: 1.1784 - accuracy: 0.6703 - val_loss: 1.1152 - val_accuracy: 0.6954 - lr: 1.0000e-04\n",
            "Epoch 9/40\n",
            "55/55 [==============================] - 8s 151ms/step - loss: 1.2028 - accuracy: 0.6611 - val_loss: 1.0788 - val_accuracy: 0.7951 - lr: 1.0000e-04\n",
            "Epoch 10/40\n",
            "55/55 [==============================] - 8s 146ms/step - loss: 1.1743 - accuracy: 0.6703 - val_loss: 1.0508 - val_accuracy: 0.7844 - lr: 1.0000e-04\n",
            "Epoch 11/40\n",
            "55/55 [==============================] - 8s 146ms/step - loss: 1.1566 - accuracy: 0.6957 - val_loss: 1.0522 - val_accuracy: 0.7763 - lr: 1.0000e-04\n",
            "Epoch 12/40\n",
            "55/55 [==============================] - 8s 145ms/step - loss: 1.1524 - accuracy: 0.6790 - val_loss: 1.0528 - val_accuracy: 0.7601 - lr: 1.0000e-04\n",
            "Epoch 13/40\n",
            "55/55 [==============================] - 8s 146ms/step - loss: 1.1222 - accuracy: 0.7032 - val_loss: 1.0591 - val_accuracy: 0.7601 - lr: 1.0000e-04\n",
            "Epoch 14/40\n",
            "55/55 [==============================] - 8s 146ms/step - loss: 1.1218 - accuracy: 0.6992 - val_loss: 1.0722 - val_accuracy: 0.7170 - lr: 1.0000e-04\n",
            "Epoch 15/40\n",
            "55/55 [==============================] - 8s 145ms/step - loss: 1.1325 - accuracy: 0.6957 - val_loss: 1.2809 - val_accuracy: 0.6199 - lr: 1.0000e-04\n",
            "Epoch 16/40\n",
            "55/55 [==============================] - 8s -2769527us/step - loss: 1.1027 - accuracy: 0.7113 - val_loss: 0.9700 - val_accuracy: 0.8113 - lr: 1.0000e-04\n",
            "Epoch 17/40\n",
            "55/55 [==============================] - 8s 145ms/step - loss: 1.1065 - accuracy: 0.7015 - val_loss: 0.9748 - val_accuracy: 0.7871 - lr: 1.0000e-04\n",
            "Epoch 18/40\n",
            "55/55 [==============================] - 8s 145ms/step - loss: 1.1159 - accuracy: 0.7067 - val_loss: 1.0982 - val_accuracy: 0.7089 - lr: 1.0000e-04\n",
            "Epoch 19/40\n",
            "55/55 [==============================] - 8s 145ms/step - loss: 1.1020 - accuracy: 0.7130 - val_loss: 1.0257 - val_accuracy: 0.7655 - lr: 1.0000e-04\n",
            "Epoch 20/40\n",
            "55/55 [==============================] - 8s 147ms/step - loss: 1.1120 - accuracy: 0.6900 - val_loss: 1.0056 - val_accuracy: 0.8059 - lr: 1.0000e-04\n",
            "Epoch 21/40\n",
            "55/55 [==============================] - 8s 147ms/step - loss: 1.1029 - accuracy: 0.7027 - val_loss: 1.0606 - val_accuracy: 0.7197 - lr: 1.0000e-04\n",
            "Epoch 22/40\n",
            "55/55 [==============================] - 8s 148ms/step - loss: 1.0840 - accuracy: 0.7073 - val_loss: 1.0539 - val_accuracy: 0.7278 - lr: 1.0000e-04\n",
            "Epoch 23/40\n",
            "55/55 [==============================] - 8s 147ms/step - loss: 1.0688 - accuracy: 0.7252 - val_loss: 1.0171 - val_accuracy: 0.7871 - lr: 3.0000e-05\n",
            "Epoch 24/40\n",
            "55/55 [==============================] - 8s -2772864us/step - loss: 1.0651 - accuracy: 0.7286 - val_loss: 1.0027 - val_accuracy: 0.7898 - lr: 3.0000e-05\n",
            "Epoch 25/40\n",
            "55/55 [==============================] - 8s 145ms/step - loss: 1.0610 - accuracy: 0.7229 - val_loss: 0.9930 - val_accuracy: 0.7844 - lr: 3.0000e-05\n",
            "Epoch 26/40\n",
            "55/55 [==============================] - 8s 151ms/step - loss: 1.0519 - accuracy: 0.7361 - val_loss: 0.9489 - val_accuracy: 0.8140 - lr: 3.0000e-05\n",
            "Epoch 27/40\n",
            "55/55 [==============================] - 8s 145ms/step - loss: 1.0471 - accuracy: 0.7309 - val_loss: 0.9722 - val_accuracy: 0.7951 - lr: 3.0000e-05\n",
            "Epoch 28/40\n",
            "55/55 [==============================] - 8s 145ms/step - loss: 1.0690 - accuracy: 0.7333 - val_loss: 1.0903 - val_accuracy: 0.6792 - lr: 3.0000e-05\n",
            "Epoch 29/40\n",
            "55/55 [==============================] - 8s 145ms/step - loss: 1.0617 - accuracy: 0.7333 - val_loss: 0.9840 - val_accuracy: 0.7817 - lr: 3.0000e-05\n",
            "Epoch 30/40\n",
            "55/55 [==============================] - 8s 145ms/step - loss: 1.0502 - accuracy: 0.7234 - val_loss: 0.9710 - val_accuracy: 0.8113 - lr: 3.0000e-05\n",
            "Epoch 31/40\n",
            "55/55 [==============================] - 8s 145ms/step - loss: 1.0397 - accuracy: 0.7367 - val_loss: 0.9740 - val_accuracy: 0.7817 - lr: 3.0000e-05\n",
            "Epoch 32/40\n",
            "55/55 [==============================] - 8s 151ms/step - loss: 1.0235 - accuracy: 0.7408 - val_loss: 0.9424 - val_accuracy: 0.8221 - lr: 3.0000e-05\n",
            "Epoch 33/40\n",
            "55/55 [==============================] - 8s 146ms/step - loss: 1.0318 - accuracy: 0.7460 - val_loss: 0.9908 - val_accuracy: 0.7817 - lr: 3.0000e-05\n",
            "Epoch 34/40\n",
            "55/55 [==============================] - 8s 146ms/step - loss: 1.0276 - accuracy: 0.7488 - val_loss: 0.9677 - val_accuracy: 0.8194 - lr: 3.0000e-05\n",
            "Epoch 35/40\n",
            "55/55 [==============================] - 8s 146ms/step - loss: 1.0276 - accuracy: 0.7552 - val_loss: 1.0190 - val_accuracy: 0.7493 - lr: 3.0000e-05\n",
            "Epoch 36/40\n",
            "55/55 [==============================] - 166s 3s/step - loss: 1.0281 - accuracy: 0.7431 - val_loss: 1.2595 - val_accuracy: 0.5633 - lr: 3.0000e-05\n",
            "Epoch 37/40\n",
            "55/55 [==============================] - -150s 147ms/step - loss: 1.0372 - accuracy: 0.7281 - val_loss: 0.9722 - val_accuracy: 0.7898 - lr: 3.0000e-05\n",
            "Epoch 38/40\n",
            "55/55 [==============================] - 8s 146ms/step - loss: 1.0120 - accuracy: 0.7460 - val_loss: 0.9487 - val_accuracy: 0.7951 - lr: 3.0000e-05\n",
            "Epoch 39/40\n",
            "55/55 [==============================] - 8s 146ms/step - loss: 1.0098 - accuracy: 0.7558 - val_loss: 0.9338 - val_accuracy: 0.7978 - lr: 9.0000e-06\n",
            "Epoch 40/40\n",
            "55/55 [==============================] - 8s 147ms/step - loss: 1.0356 - accuracy: 0.7419 - val_loss: 0.9333 - val_accuracy: 0.8005 - lr: 9.0000e-06\n",
            "âœ… Pepper concluÃ­do! Melhor accuracy: 0.8221\n",
            "\n",
            "ðŸŽ¯ TODOS OS MODELOS TREINADOS COM SUCESSO!\n"
          ]
        }
      ],
      "source": [
        "# 3. TREINAMENTO OTIMIZADO COM CLASS WEIGHTS\n",
        "def treinar_modelo_binario(modelo, especie, train_gen, val_gen, class_weights):\n",
        "    \"\"\"Treina modelo de classificaÃ§Ã£o binÃ¡ria com class weights\"\"\"\n",
        "    print(f\"\\nðŸš€ Treinando {especie}...\")\n",
        "    \n",
        "    # CompilaÃ§Ã£o\n",
        "    modelo.compile(\n",
        "        optimizer=Adam(learning_rate=0.0001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    # Callback\n",
        "    callbacks = [\n",
        "        EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=15,\n",
        "            restore_best_weights=True,\n",
        "            min_delta=0.001\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.3,\n",
        "            patience=6,\n",
        "            min_lr=1e-8\n",
        "        ),\n",
        "        ModelCheckpoint(\n",
        "            filepath=f'modelos_salvos/especialistas/modelo_binario_{especie.lower()}.h5',\n",
        "            monitor='val_accuracy',\n",
        "            save_best_only=True\n",
        "        )\n",
        "    ]\n",
        "    \n",
        "    # Treinamento\n",
        "    history = modelo.fit(\n",
        "        train_gen,\n",
        "        epochs=40,\n",
        "        validation_data=val_gen,\n",
        "        class_weight=class_weights,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "    \n",
        "    final_accuracy = max(history.history['val_accuracy'])\n",
        "    print(f\"âœ… {especie} concluÃ­do! Melhor accuracy: {final_accuracy:.4f}\")\n",
        "    \n",
        "    return history\n",
        "\n",
        "# Treinar todos os modelos\n",
        "os.makedirs('modelos_salvos', exist_ok=True)\n",
        "\n",
        "print(\"=== TREINAMENTO DOS MODELOS BINÃRIOS ===\")\n",
        "history_tomato = treinar_modelo_binario(modelo_tomato, 'Tomato', train_gen_tomato, val_gen_tomato, cw_tomato)\n",
        "history_potato = treinar_modelo_binario(modelo_potato, 'Potato', train_gen_potato, val_gen_potato, cw_potato)\n",
        "history_pepper = treinar_modelo_binario(modelo_pepper, 'Pepper', train_gen_pepper, val_gen_pepper, cw_pepper)\n",
        "\n",
        "print(\"\\nðŸŽ¯ TODOS OS MODELOS TREINADOS COM SUCESSO!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== AVALIAÃ‡ÃƒO FINAL DOS MODELOS BINÃRIOS ===\n",
            "\n",
            "ðŸ“Š Avaliando Tomato...\n",
            "   ðŸŽ¯ Accuracy: 0.9409\n",
            "   ðŸŽ¯ AUC-ROC: 0.9501\n",
            "   ðŸŽ¯ Recall: 0.9847\n",
            "   ðŸŽ¯ Precision: 0.9513\n",
            "   ðŸŽ¯ F1-Score: 0.9677\n",
            "   Matriz: [[130, 109], [ 33, 2130]]\n",
            "\n",
            "   Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Healthy       0.80      0.54      0.65       239\n",
            "   Unhealthy       0.95      0.98      0.97      2163\n",
            "\n",
            "    accuracy                           0.94      2402\n",
            "   macro avg       0.87      0.76      0.81      2402\n",
            "weighted avg       0.94      0.94      0.94      2402\n",
            "\n",
            "\n",
            "ðŸ“Š Avaliando Potato...\n",
            "   ðŸŽ¯ Accuracy: 0.9288\n",
            "   ðŸŽ¯ AUC-ROC: 0.4975\n",
            "   ðŸŽ¯ Recall: 1.0000\n",
            "   ðŸŽ¯ Precision: 0.9288\n",
            "   ðŸŽ¯ F1-Score: 0.9631\n",
            "   Matriz: [[  0,  23], [  0, 300]]\n",
            "\n",
            "   Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Healthy       0.00      0.00      0.00        23\n",
            "   Unhealthy       0.93      1.00      0.96       300\n",
            "\n",
            "    accuracy                           0.93       323\n",
            "   macro avg       0.46      0.50      0.48       323\n",
            "weighted avg       0.86      0.93      0.89       323\n",
            "\n",
            "\n",
            "ðŸ“Š Avaliando Pepper...\n",
            "   ðŸŽ¯ Accuracy: 0.7984\n",
            "   ðŸŽ¯ AUC-ROC: 0.8764\n",
            "   ðŸŽ¯ Recall: 0.6067\n",
            "   ðŸŽ¯ Precision: 0.8505\n",
            "   ðŸŽ¯ F1-Score: 0.7082\n",
            "   Matriz: [[206,  16], [ 59,  91]]\n",
            "\n",
            "   Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Healthy       0.78      0.93      0.85       222\n",
            "   Unhealthy       0.85      0.61      0.71       150\n",
            "\n",
            "    accuracy                           0.80       372\n",
            "   macro avg       0.81      0.77      0.78       372\n",
            "weighted avg       0.81      0.80      0.79       372\n",
            "\n",
            "\n",
            "=== COMPARAÃ‡ÃƒO FINAL ===\n",
            "   Tomato: 0.9409 - ðŸŸ¢ EXCELENTE\n",
            "   Potato: 0.9288 - ðŸŸ¢ EXCELENTE\n",
            "   Pepper: 0.7984 - ðŸŸ¡ BOA\n"
          ]
        }
      ],
      "source": [
        "# 4. AVALIAÃ‡ÃƒO DO MODELO\n",
        "from sklearn.metrics import (\n",
        "    classification_report, \n",
        "    accuracy_score, \n",
        "    confusion_matrix, \n",
        "    roc_auc_score, \n",
        "    recall_score, \n",
        "    precision_score, \n",
        "    f1_score\n",
        "    )\n",
        "\n",
        "def avaliar_modelo(modelo, especie, test_gen, dataset_test):\n",
        "    \"\"\"AvaliaÃ§Ã£o completa do modelo de classificaÃ§Ã£o binÃ¡ria\"\"\"\n",
        "    print(f\"\\nðŸ“Š Avaliando {especie}...\")\n",
        "    \n",
        "    test_gen.reset()\n",
        "    \n",
        "    # PrediÃ§Ãµes\n",
        "    predictions_prob = modelo.predict(test_gen, verbose=0)\n",
        "    predictions_class = (predictions_prob > 0.5).astype(int).flatten()\n",
        "    \n",
        "    # Classes verdadeiras\n",
        "    true_classes = [1 if label == 'unhealthy' else 0 for label in dataset_test['y']]\n",
        "    \n",
        "    # MÃ©tricas\n",
        "    accuracy = accuracy_score(true_classes, predictions_class)\n",
        "    auc_score = roc_auc_score(true_classes, predictions_prob)\n",
        "    cm = confusion_matrix(true_classes, predictions_class)\n",
        "    recall = recall_score(true_classes, predictions_class)\n",
        "    precision = precision_score(true_classes, predictions_class)\n",
        "    f1 = f1_score(true_classes, predictions_class)\n",
        "\n",
        "    # MÃ©tricas mÃ©dicas\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    \n",
        "    print(f\"   ðŸŽ¯ Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"   ðŸŽ¯ AUC-ROC: {auc_score:.4f}\")\n",
        "    print(f\"   ðŸŽ¯ Recall: {recall:.4f}\")\n",
        "    print(f\"   ðŸŽ¯ Precision: {precision:.4f}\")\n",
        "    print(f\"   ðŸŽ¯ F1-Score: {f1:.4f}\")\n",
        "\n",
        "    \n",
        "    # Matriz de confusÃ£o\n",
        "    print(f\"   Matriz: [[{tn:3d}, {fp:3d}], [{fn:3d}, {tp:3d}]]\")\n",
        "    \n",
        "    # RelatÃ³rio\n",
        "    print(\"\\n   Classification Report:\")\n",
        "    print(classification_report(true_classes, predictions_class, target_names=['Healthy', 'Unhealthy'], zero_division=0))\n",
        "    \n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'auc_roc': auc_score,\n",
        "        'confusion_matrix': cm,\n",
        "        'recall': recall,\n",
        "        'precision': precision,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "# Avaliar todos os modelos\n",
        "print(\"=== AVALIAÃ‡ÃƒO FINAL DOS MODELOS BINÃRIOS ===\")\n",
        "resultados_tomato = avaliar_modelo(modelo_tomato, 'Tomato', test_gen_tomato, dataset_tomato['test'])\n",
        "resultados_potato = avaliar_modelo(modelo_potato, 'Potato', test_gen_potato, dataset_potato['test'])\n",
        "resultados_pepper = avaliar_modelo(modelo_pepper, 'Pepper', test_gen_pepper, dataset_pepper['test'])\n",
        "\n",
        "# ComparaÃ§Ã£o final\n",
        "print(f\"\\n=== COMPARAÃ‡ÃƒO FINAL ===\")\n",
        "resultados = [\n",
        "    ('Tomato', resultados_tomato),\n",
        "    ('Potato', resultados_potato), \n",
        "    ('Pepper', resultados_pepper)\n",
        "]\n",
        "\n",
        "for especie, resultado in resultados:\n",
        "    qualidade = \"ðŸŸ¢ EXCELENTE\" if resultado['accuracy'] > 0.9 else \"ðŸŸ¡ BOA\" if resultado['accuracy'] > 0.7 else \"ðŸ”´ INSUFICIENTE\"\n",
        "    print(f\"   {especie}: {resultado['accuracy']:.4f} - {qualidade}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Salvar modelos finais\n",
        "print(\"SALVANDO MODELOS OTIMIZADOS\")\n",
        "modelo_tomato.save('modelos_salvos/especialistas/especialista_tomato_binario_final.h5')\n",
        "modelo_potato.save('modelos_salvos/especialistas/especialista_potato_binario_final.h5')\n",
        "modelo_pepper.save('modelos_salvos/especialistas/especialista_pepper_binario_final.h5')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf-gpu-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
